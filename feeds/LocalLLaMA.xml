<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>/r/LocalLLaMA/.rss</id>
  <title>LocalLlama</title>
  <updated>2025-06-12T18:25:32+00:00</updated>
  <link href="https://old.reddit.com/r/LocalLLaMA/" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator>
  <icon>https://www.redditstatic.com/icon.png/</icon>
  <subtitle>Subreddit to discuss Llama, the large language model created by Meta AI.</subtitle>
  <entry>
    <id>t3_1l8pem0</id>
    <title>I finally got rid of Ollama!</title>
    <updated>2025-06-11T10:42:52+00:00</updated>
    <author>
      <name>/u/relmny</name>
      <uri>https://old.reddit.com/user/relmny</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;About a month ago, I decided to move away from Ollama (while still using Open WebUI as frontend), and I actually did it faster and easier than I thought!&lt;/p&gt; &lt;p&gt;Since then, my setup has been (on both Linux and Windows):&lt;/p&gt; &lt;p&gt;llama.cpp or ik_llama.cpp for inference&lt;/p&gt; &lt;p&gt;llama-swap to load/unload/auto-unload models (have a big config.yaml file with all the models and parameters like for think/no_think, etc) &lt;/p&gt; &lt;p&gt;Open Webui as the frontend. In its &amp;quot;workspace&amp;quot; I have all the models (although not needed, because with llama-swap, Open Webui will list all the models in the drop list, but I prefer to use it) configured with the system prompts and so. So I just select whichever I want from the drop list or from the &amp;quot;workspace&amp;quot; and llama-swap loads (or unloads the current one and loads the new one) the model. &lt;/p&gt; &lt;p&gt;No more weird location/names for the models (I now just &amp;quot;wget&amp;quot; from huggingface to whatever folder I want and, if needed, I could even use them with other engines), or other &amp;quot;features&amp;quot; from Ollama. &lt;/p&gt; &lt;p&gt;Big thanks to llama.cpp (as always), ik_llama.cpp, llama-swap and Open Webui! (and huggingface and &lt;a href="/r/localllama"&gt;r/localllama&lt;/a&gt; of course!)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/relmny"&gt; /u/relmny &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l8pem0/i_finally_got_rid_of_ollama/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l8pem0/i_finally_got_rid_of_ollama/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1l8pem0/i_finally_got_rid_of_ollama/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-06-11T10:42:52+00:00</published>
  </entry>
  <entry>
    <id>t3_1l8umf2</id>
    <title>Meta releases V-JEPA 2, the first world model trained on video</title>
    <updated>2025-06-11T14:48:35+00:00</updated>
    <author>
      <name>/u/juanviera23</name>
      <uri>https://old.reddit.com/user/juanviera23</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l8umf2/meta_releases_vjepa_2_the_first_world_model/"&gt; &lt;img alt="Meta releases V-JEPA 2, the first world model trained on video" src="https://external-preview.redd.it/XYCW87FCFGR0wI2hYDorldwWOlBC0pjIIfGLZhngZC4.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=5011249fce4c8240f4cce7fe71a892b4c008780b" title="Meta releases V-JEPA 2, the first world model trained on video" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/juanviera23"&gt; /u/juanviera23 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://huggingface.co/collections/facebook/v-jepa-2-6841bad8413014e185b497a6"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l8umf2/meta_releases_vjepa_2_the_first_world_model/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1l8umf2/meta_releases_vjepa_2_the_first_world_model/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-06-11T14:48:35+00:00</published>
  </entry>
  <entry>
    <id>t3_1l99pih</id>
    <title>Mistral-Nemotron?</title>
    <updated>2025-06-12T01:13:30+00:00</updated>
    <author>
      <name>/u/mj3815</name>
      <uri>https://old.reddit.com/user/mj3815</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Looks like Nvidia is hosting a new model but I can't find any information about it on Mistral's website?&lt;/p&gt; &lt;p&gt;&lt;a href="https://docs.api.nvidia.com/nim/reference/mistralai-mistral-nemotron"&gt;https://docs.api.nvidia.com/nim/reference/mistralai-mistral-nemotron&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://build.nvidia.com/mistralai/mistral-nemotron/modelcard"&gt;https://build.nvidia.com/mistralai/mistral-nemotron/modelcard&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/mj3815"&gt; /u/mj3815 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l99pih/mistralnemotron/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l99pih/mistralnemotron/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1l99pih/mistralnemotron/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-06-12T01:13:30+00:00</published>
  </entry>
  <entry>
    <id>t3_1l9b04q</id>
    <title>Local organic rig</title>
    <updated>2025-06-12T02:17:01+00:00</updated>
    <author>
      <name>/u/Both-Indication5062</name>
      <uri>https://old.reddit.com/user/Both-Indication5062</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9b04q/local_organic_rig/"&gt; &lt;img alt="Local organic rig" src="https://preview.redd.it/78c6uej5oe6f1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=a1c646a11de430e9f56e2ed6e1e19a1e1cd01f56" title="Local organic rig" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;local organic ai rig&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Both-Indication5062"&gt; /u/Both-Indication5062 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/78c6uej5oe6f1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9b04q/local_organic_rig/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1l9b04q/local_organic_rig/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-06-12T02:17:01+00:00</published>
  </entry>
  <entry>
    <id>t3_1l9ndp2</id>
    <title>Using LLM's with Home Assistant + Voice Integration</title>
    <updated>2025-06-12T14:07:07+00:00</updated>
    <author>
      <name>/u/nat2r</name>
      <uri>https://old.reddit.com/user/nat2r</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Looking to set up home assistant at home with a LLM connected to make the assistant more conversational. It doesn't need to have superior depth of knowledge, but I am looking for something that can respond creatively, conversationally, dynamically to a variety of requests centered around IoT tasks. In my head this is something like Qwen3 8B or 14B. &lt;/p&gt; &lt;p&gt;Are there any NUCs/MiniPC's that would fit the bill here? Is it often recommended that the LLM be hosted on separate hardware from the Home Assistant server? &lt;/p&gt; &lt;p&gt;In the long term I'd like to explore a larger system to accommodate something more comprehensive for general use, but in the near term I'd like to start playing with this project. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/nat2r"&gt; /u/nat2r &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9ndp2/using_llms_with_home_assistant_voice_integration/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9ndp2/using_llms_with_home_assistant_voice_integration/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1l9ndp2/using_llms_with_home_assistant_voice_integration/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-06-12T14:07:07+00:00</published>
  </entry>
  <entry>
    <id>t3_1l9blur</id>
    <title>[2506.06105] Text-to-LoRA: Instant Transformer Adaption</title>
    <updated>2025-06-12T02:47:41+00:00</updated>
    <author>
      <name>/u/Thrumpwart</name>
      <uri>https://old.reddit.com/user/Thrumpwart</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Thrumpwart"&gt; /u/Thrumpwart &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://arxiv.org/abs/2506.06105"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9blur/250606105_texttolora_instant_transformer_adaption/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1l9blur/250606105_texttolora_instant_transformer_adaption/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-06-12T02:47:41+00:00</published>
  </entry>
  <entry>
    <id>t3_1l97fst</id>
    <title>OpenAI performs KYC to use the latest o3-pro via API</title>
    <updated>2025-06-11T23:24:00+00:00</updated>
    <author>
      <name>/u/Mr_Moonsilver</name>
      <uri>https://old.reddit.com/user/Mr_Moonsilver</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;This afternoon I cobbled together a test-script to mess around with o3-pro. Looked nice, so nice that I came back this evening to give it another go. The OpenAI sdk throws an error in the terminal, prompting me &amp;quot;Your organization must be verified to stream this model.&amp;quot;&lt;/p&gt; &lt;p&gt;Allright, I go to OpenAI platform and lo and behold, a full blown KYC process kicks off, with ID scanning, face scanning, all that shite. Damn, has this gone far. Really hope DeepSeek delivers another blow with R2 to put an end to this.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Mr_Moonsilver"&gt; /u/Mr_Moonsilver &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l97fst/openai_performs_kyc_to_use_the_latest_o3pro_via/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l97fst/openai_performs_kyc_to_use_the_latest_o3pro_via/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1l97fst/openai_performs_kyc_to_use_the_latest_o3pro_via/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-06-11T23:24:00+00:00</published>
  </entry>
  <entry>
    <id>t3_1l9rcoj</id>
    <title>Seedance 1.0</title>
    <updated>2025-06-12T16:47:04+00:00</updated>
    <author>
      <name>/u/kamikazechaser</name>
      <uri>https://old.reddit.com/user/kamikazechaser</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/kamikazechaser"&gt; /u/kamikazechaser &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://seed.bytedance.com/en/seedance"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9rcoj/seedance_10/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1l9rcoj/seedance_10/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-06-12T16:47:04+00:00</published>
  </entry>
  <entry>
    <id>t3_1l9demc</id>
    <title>Testing Mac Studio 512 GB, 4 TB SSD, M3 Ultra w 32 cores.</title>
    <updated>2025-06-12T04:25:33+00:00</updated>
    <author>
      <name>/u/Deviad</name>
      <uri>https://old.reddit.com/user/Deviad</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9demc/testing_mac_studio_512_gb_4_tb_ssd_m3_ultra_w_32/"&gt; &lt;img alt="Testing Mac Studio 512 GB, 4 TB SSD, M3 Ultra w 32 cores." src="https://b.thumbs.redditmedia.com/YojFokLeZzbNOpT7rZaaYJlRnoALjFvRgIII2E0FV3I.jpg" title="Testing Mac Studio 512 GB, 4 TB SSD, M3 Ultra w 32 cores." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hi all,&lt;br /&gt; I am running some tests and to be fair, I don't regret it.&lt;br /&gt; Given that I want to learn and sell private AI solutions, and I want to run K8s clusters of agents locally for learning purposes, I think it's a good investment medium/long term.&lt;/p&gt; &lt;p&gt;24 tokens/second for Qwen3 235b, in thinking mode, is totally manageable and anyways that's when you need something complex.&lt;/p&gt; &lt;p&gt;If you use /nothink the response will be finalized in a short amount of time and for tasks like give me the boilerplate code for xyz, it's totally manageable.&lt;/p&gt; &lt;p&gt;Now I am downloading the latest R1, let's see how it goes with that.&lt;/p&gt; &lt;p&gt;Therefore, if you are waiting for M5 whatever, you are just wasting time which you could invest into learning and be there first.&lt;br /&gt; Not to mention the latest news about OpenAI being forced to log requests because of a NY court order being issued after a lawsuit started by The NY Times.&lt;br /&gt; I don't feel good thinking that when I type something into Claude or ChatGPT they may be learning from my questions.&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/qf0zh629df6f1.png?width=1766&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ededfa911a12e12a061122f517f2fcd2a13d9f02"&gt;Qwen3 235b MLX w thinking&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/tn9gcg0cdf6f1.png?width=1704&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=112db305678d4210ae187e7b172223e605394e1d"&gt;Qwen3 235b MLX w/o thinking&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Deviad"&gt; /u/Deviad &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9demc/testing_mac_studio_512_gb_4_tb_ssd_m3_ultra_w_32/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9demc/testing_mac_studio_512_gb_4_tb_ssd_m3_ultra_w_32/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1l9demc/testing_mac_studio_512_gb_4_tb_ssd_m3_ultra_w_32/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-06-12T04:25:33+00:00</published>
  </entry>
  <entry>
    <id>t3_1l9oyt7</id>
    <title>[update] Restructured repo under rvn-tools ‚Äî modular CLI for LLM formats</title>
    <updated>2025-06-12T15:12:30+00:00</updated>
    <author>
      <name>/u/rvnllm</name>
      <uri>https://old.reddit.com/user/rvnllm</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Quick update.&lt;/p&gt; &lt;p&gt;Yesterday I posted about `rvn-convert`, a Rust tool for converting safetensors to GGUF.&lt;/p&gt; &lt;p&gt;While fixing bugs today, I also restructured the project under `rvn-tools` - a modular, CLI-oriented Rust-native toolkit for LLM model formats, inference workflows, and data pipelines.&lt;/p&gt; &lt;p&gt;What's in so far:&lt;/p&gt; &lt;p&gt;- safetensor -&amp;gt; GGUF converter (initial implementation)&lt;/p&gt; &lt;p&gt;- CLI layout with `clap`, shard parsing, typed metadata handling&lt;/p&gt; &lt;p&gt;- Makefile-based workflow (fmt, clippy, release, test, etc.)&lt;/p&gt; &lt;p&gt;Focus:&lt;/p&gt; &lt;p&gt;- Fully open, minimal, and performant&lt;/p&gt; &lt;p&gt;- Memory mapped operations, zero copy, zero move&lt;/p&gt; &lt;p&gt;- Built for **local inference**, not cloud-bloat&lt;/p&gt; &lt;p&gt;- Python bindings planned via `pyo3` (coming soon)&lt;/p&gt; &lt;p&gt;Next steps:&lt;/p&gt; &lt;p&gt;- tokenizer tooling&lt;/p&gt; &lt;p&gt;- qkv and other debugging tooling&lt;/p&gt; &lt;p&gt;- tensor validator / preprocessor&lt;/p&gt; &lt;p&gt;- some other ideas I go along&lt;/p&gt; &lt;p&gt;Open to feedback or bug reports or ideas.&lt;/p&gt; &lt;p&gt;Repo: (repo)[&lt;a href="https://github.com/rvnllm/rvn-tools%5C"&gt;https://github.com/rvnllm/rvn-tools\&lt;/a&gt;]&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/rvnllm"&gt; /u/rvnllm &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9oyt7/update_restructured_repo_under_rvntools_modular/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9oyt7/update_restructured_repo_under_rvntools_modular/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1l9oyt7/update_restructured_repo_under_rvntools_modular/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-06-12T15:12:30+00:00</published>
  </entry>
  <entry>
    <id>t3_1l8zssy</id>
    <title>Disney and Universal sue AI image company Midjourney for unlicensed use of Star Wars, The Simpsons and more</title>
    <updated>2025-06-11T18:11:52+00:00</updated>
    <author>
      <name>/u/Iory1998</name>
      <uri>https://old.reddit.com/user/Iory1998</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;This is big! When Disney gets involved, shit is about to hit the fan. &lt;/p&gt; &lt;p&gt;If they come after Midourney, then expect other AI labs trained on similar training data to be hit soon. &lt;/p&gt; &lt;p&gt;What do you think?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Iory1998"&gt; /u/Iory1998 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l8zssy/disney_and_universal_sue_ai_image_company/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l8zssy/disney_and_universal_sue_ai_image_company/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1l8zssy/disney_and_universal_sue_ai_image_company/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-06-11T18:11:52+00:00</published>
  </entry>
  <entry>
    <id>t3_1l9m32y</id>
    <title>Spy search: Open source that faster than perplexity</title>
    <updated>2025-06-12T13:10:24+00:00</updated>
    <author>
      <name>/u/jasonhon2013</name>
      <uri>https://old.reddit.com/user/jasonhon2013</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9m32y/spy_search_open_source_that_faster_than_perplexity/"&gt; &lt;img alt="Spy search: Open source that faster than perplexity" src="https://external-preview.redd.it/mF7cGFuCHvTPCF2PosrefDlSXoaQ7svn_kltQIq6Dac.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=0b8fbdb36c3e6484af6fc5fab2652c43cce55f42" title="Spy search: Open source that faster than perplexity" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I am really happy !!! My open source is somehow faster than perplexity yeahhhh so happy. Really really happy and want to share with you guys !! ( :( someone said it's copy paste they just never ever use mistral + 5090 :)))) &amp;amp; of course they don't even look at my open source hahahah )&lt;/p&gt; &lt;p&gt;&lt;a href="https://reddit.com/link/1l9m32y/video/bf99fvbmwh6f1/player"&gt;https://reddit.com/link/1l9m32y/video/bf99fvbmwh6f1/player&lt;/a&gt;&lt;/p&gt; &lt;p&gt;url: &lt;a href="https://github.com/JasonHonKL/spy-search"&gt;https://github.com/JasonHonKL/spy-search&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/jasonhon2013"&gt; /u/jasonhon2013 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9m32y/spy_search_open_source_that_faster_than_perplexity/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9m32y/spy_search_open_source_that_faster_than_perplexity/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1l9m32y/spy_search_open_source_that_faster_than_perplexity/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-06-12T13:10:24+00:00</published>
  </entry>
  <entry>
    <id>t3_1l9cd44</id>
    <title>Mistral.rs v0.6.0 now has full built-in MCP Client support!</title>
    <updated>2025-06-12T03:27:42+00:00</updated>
    <author>
      <name>/u/EricBuehler</name>
      <uri>https://old.reddit.com/user/EricBuehler</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9cd44/mistralrs_v060_now_has_full_builtin_mcp_client/"&gt; &lt;img alt="Mistral.rs v0.6.0 now has full built-in MCP Client support!" src="https://external-preview.redd.it/2lLo8jhJSmFII5np0CAVlto_8NREWNjCUymEN6xCnKk.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=dd943325186c8dbc22ef59b4adb920ee2ccdc473" title="Mistral.rs v0.6.0 now has full built-in MCP Client support!" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hey all! Just shipped what I think is a game-changer for local LLM workflows: MCP (Model Context Protocol) client support in &lt;a href="https://github.com/EricLBuehler/mistral.rs/"&gt;mistral.rs&lt;/a&gt; (&lt;a href="https://github.com/EricLBuehler/mistral.rs"&gt;https://github.com/EricLBuehler/mistral.rs&lt;/a&gt;)! It is built-in and closely integrated, which makes the process of developing MCP-powered apps easy and fast.&lt;/p&gt; &lt;p&gt;You can get &lt;a href="https://github.com/EricLBuehler/mistral.rs/blob/master/mistralrs-pyo3/_README.md#installation-from-pypi"&gt;mistralrs via PyPi&lt;/a&gt;, &lt;a href="https://github.com/EricLBuehler/mistral.rs/pkgs/container/mistral.rs"&gt;Docker Containers&lt;/a&gt;, or with &lt;a href="https://github.com/EricLBuehler/mistral.rs?tab=readme-ov-file#installation-and-build"&gt;a local build&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;What does this mean?&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Your models can now automatically connect to external tools and services - file systems, web search, databases, APIs, you name it.&lt;/p&gt; &lt;p&gt;No more manual tool calling setup, no more custom integration code.&lt;/p&gt; &lt;p&gt;Just configure once and your models gain superpowers.&lt;/p&gt; &lt;p&gt;We support all the transport interfaces:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Process&lt;/strong&gt;: Local tools (filesystem, databases, and more)&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Streamable HTTP and SSE&lt;/strong&gt;: REST APIs, cloud services - Works with &lt;em&gt;any&lt;/em&gt; HTTP MCP server&lt;/li&gt; &lt;li&gt;&lt;strong&gt;WebSocket&lt;/strong&gt;: Real-time streaming tools&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;The best part?&lt;/strong&gt; &lt;strong&gt;&lt;em&gt;It just works.&lt;/em&gt;&lt;/strong&gt; Tools are discovered automatically at startup, and support for multiserver, authentication handling, and timeouts are designed to make the experience easy.&lt;/p&gt; &lt;p&gt;I've been testing this extensively and it's incredibly smooth. The Python API feels natural, HTTP server integration is seamless, and the automatic tool discovery means no more maintaining tool registries.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Using the MCP support in Python:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/2c2v74bt0f6f1.png?width=1274&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=bd180e59597f04103b7af5acc03b0983a4d41c04"&gt;https://preview.redd.it/2c2v74bt0f6f1.png?width=1274&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=bd180e59597f04103b7af5acc03b0983a4d41c04&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Use the HTTP server in just 2 steps:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;1) Create mcp-config.json&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;{ &amp;quot;servers&amp;quot;: [ { &amp;quot;name&amp;quot;: &amp;quot;Filesystem Tools&amp;quot;, &amp;quot;source&amp;quot;: { &amp;quot;type&amp;quot;: &amp;quot;Process&amp;quot;, &amp;quot;command&amp;quot;: &amp;quot;npx&amp;quot;, &amp;quot;args&amp;quot;: [ &amp;quot;@modelcontextprotocol/server-filesystem&amp;quot;, &amp;quot;.&amp;quot; ] } } ], &amp;quot;auto_register_tools&amp;quot;: true } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;2) Start server:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;mistralrs-server --mcp-config mcp-config.json --port 1234 run -m Qwen/Qwen3-4B&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;You can just use the normal OpenAI API - tools work automatically!&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;curl -X POST http://localhost:1234/v1/chat/completions \ -H &amp;quot;Content-Type: application/json&amp;quot; \ -d '{ &amp;quot;model&amp;quot;: &amp;quot;mistral.rs&amp;quot;, &amp;quot;messages&amp;quot;: [ { &amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: &amp;quot;List files and create hello.txt&amp;quot; } ] }' &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;a href="https://reddit.com/link/1l9cd44/video/i9ttdu2v0f6f1/player"&gt;https://reddit.com/link/1l9cd44/video/i9ttdu2v0f6f1/player&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I'm excited to see what you create with this üöÄ! Let me know what you think.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Quick links:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://github.com/EricLBuehler/mistral.rs/blob/master/examples/MCP_QUICK_START.md"&gt;https://github.com/EricLBuehler/mistral.rs/blob/master/examples/MCP_QUICK_START.md&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/EricLBuehler/mistral.rs/tree/master/docs/MCP"&gt;https://github.com/EricLBuehler/mistral.rs/tree/master/docs/MCP&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/EricLBuehler/mistral.rs/blob/master/examples/python/mcp_client.py"&gt;https://github.com/EricLBuehler/mistral.rs/blob/master/examples/python/mcp_client.py&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/EricBuehler"&gt; /u/EricBuehler &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9cd44/mistralrs_v060_now_has_full_builtin_mcp_client/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9cd44/mistralrs_v060_now_has_full_builtin_mcp_client/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1l9cd44/mistralrs_v060_now_has_full_builtin_mcp_client/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-06-12T03:27:42+00:00</published>
  </entry>
  <entry>
    <id>t3_1l9m6dc</id>
    <title>[Update] Emotionally-Aware VN Dialogue Dataset ‚Äì Deep Context Tagging, ShareGPT-Style Structure</title>
    <updated>2025-06-12T13:14:39+00:00</updated>
    <author>
      <name>/u/Akowmako</name>
      <uri>https://old.reddit.com/user/Akowmako</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hey again everyone, Following up on my earlier posts about converting a visual novel script into a fine-tuning dataset, I‚Äôve gone back and improved the format significantly thanks to feedback here.&lt;/p&gt; &lt;p&gt;The goal is the same: create expressive, roleplay-friendly dialogue data that captures emotion, tone, character personality, and nuance, especially for dere-type characters and NSFW/SFW variation.&lt;/p&gt; &lt;p&gt;VOl 0 is only SFW &lt;/p&gt; &lt;p&gt;‚Ä¢ What‚Äôs New:&lt;/p&gt; &lt;p&gt;Improved JSON structure, closer to ShareGPT format&lt;/p&gt; &lt;p&gt;More consistent tone/emotion tagging&lt;/p&gt; &lt;p&gt;Added deeper context awareness (4 lines before/after)&lt;/p&gt; &lt;p&gt;Preserved expressive elements (onomatopoeia, stutters, laughs)&lt;/p&gt; &lt;p&gt;Categorized dere-type and added voice/personality cues&lt;/p&gt; &lt;p&gt;‚Ä¢ Why?&lt;/p&gt; &lt;p&gt;Because tagging a line as just ‚Äúlaughing‚Äù misses everything. Was it sarcasm? Pain? Joy? I want models to understand motivation and emotional flow ‚Äî not just parrot words.&lt;/p&gt; &lt;p&gt;Example (same as before to show improvement):&lt;/p&gt; &lt;p&gt;Flat version:&lt;/p&gt; &lt;p&gt;{ &amp;quot;instruction&amp;quot;: &amp;quot;What does Maple say?&amp;quot;,&lt;/p&gt; &lt;p&gt;&amp;quot;output&amp;quot;: &amp;quot;Oopsie! I accidentally splashed some hot water on you! Sorry about that~ Ahahah-- Owwww!!&amp;quot;,&lt;/p&gt; &lt;p&gt;&amp;quot;metadata&amp;quot;: { &amp;quot;character&amp;quot;: &amp;quot;Maple&amp;quot;, &amp;quot;emotion&amp;quot;: &amp;quot;laughing&amp;quot; &lt;/p&gt; &lt;p&gt;&amp;quot;tone&amp;quot;: &amp;quot;apologetic&amp;quot; }&lt;/p&gt; &lt;p&gt;}&lt;/p&gt; &lt;p&gt;‚Ä¢ Updated version with context:&lt;/p&gt; &lt;pre&gt;&lt;code&gt; { &amp;quot;from&amp;quot;: &amp;quot;char_metadata&amp;quot;, &amp;quot;value&amp;quot;: { &amp;quot;character_name&amp;quot;: &amp;quot;Azuki&amp;quot;, &amp;quot;persona&amp;quot;: &amp;quot;Azuki is a fiery, tomboyish...&amp;quot;, &amp;quot;dere_type&amp;quot;: &amp;quot;tsundere&amp;quot;, &amp;quot;current_emotion&amp;quot;: &amp;quot;mocking, amused, pain&amp;quot;, &amp;quot;tone&amp;quot;: &amp;quot;taunting, surprised&amp;quot; } }, { &amp;quot;from&amp;quot;: &amp;quot;char&amp;quot;, &amp;quot;value&amp;quot;: &amp;quot;You're a NEET catgirl who can only eat, sleep, and play! Huehuehueh, whooaaa!! Aagh, that's hotttt!!!&amp;quot; }, { &amp;quot;from&amp;quot;: &amp;quot;char_metadata&amp;quot;, &amp;quot;value&amp;quot;: { &amp;quot;character_name&amp;quot;: &amp;quot;Maple&amp;quot;, &amp;quot;persona&amp;quot;: &amp;quot;Maple is a prideful, sophisticated catgirl...&amp;quot;, &amp;quot;dere_type&amp;quot;: &amp;quot;himidere&amp;quot;, &amp;quot;current_emotion&amp;quot;: &amp;quot;malicious glee, feigned innocence, pain&amp;quot;, &amp;quot;tone&amp;quot;: &amp;quot;sarcastic, surprised&amp;quot; } }, { &amp;quot;from&amp;quot;: &amp;quot;char&amp;quot;, &amp;quot;value&amp;quot;: &amp;quot;Oopsie! I accidentally splashed some hot water on you! Sorry about that~ Ahahah-- Owwww!!&amp;quot; }, { &amp;quot;from&amp;quot;: &amp;quot;char_metadata&amp;quot;, &amp;quot;value&amp;quot;: { &amp;quot;character_name&amp;quot;: &amp;quot;Azuki&amp;quot;, &amp;quot;persona&amp;quot;: &amp;quot;Azuki is a fiery, tomboyish...&amp;quot;, &amp;quot;dere_type&amp;quot;: &amp;quot;tsundere&amp;quot;, &amp;quot;current_emotion&amp;quot;: &amp;quot;retaliatory, gleeful&amp;quot;, &amp;quot;tone&amp;quot;: &amp;quot;sarcastic&amp;quot; } }, { &amp;quot;from&amp;quot;: &amp;quot;char&amp;quot;, &amp;quot;value&amp;quot;: &amp;quot;Heh, my bad! My paw just flew right at'cha! Hahaha!&amp;quot; } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;‚Ä¢ Outcome&lt;/p&gt; &lt;p&gt;This dataset now lets a model:&lt;/p&gt; &lt;p&gt;Match dere-type voices with appropriate phrasing&lt;/p&gt; &lt;p&gt;Preserve emotional realism in both SFW and NSFW contexts&lt;/p&gt; &lt;p&gt;Move beyond basic emotion labels to expressive patterns (tsundere teasing, onomatopoeia, flustered laughter, etc.)&lt;/p&gt; &lt;p&gt;It‚Äôs still a work in progress (currently ~3MB, will grow, dialogs only without JSON yet), and more feedback is welcome. Just wanted to share the next step now that the format is finally usable and consistent.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Akowmako"&gt; /u/Akowmako &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9m6dc/update_emotionallyaware_vn_dialogue_dataset_deep/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9m6dc/update_emotionallyaware_vn_dialogue_dataset_deep/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1l9m6dc/update_emotionallyaware_vn_dialogue_dataset_deep/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-06-12T13:14:39+00:00</published>
  </entry>
  <entry>
    <id>t3_1l9jm52</id>
    <title>A new swarm-style distributed pretraining architecture has just launched, working on a 15B model</title>
    <updated>2025-06-12T11:02:57+00:00</updated>
    <author>
      <name>/u/emission-control</name>
      <uri>https://old.reddit.com/user/emission-control</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Macrocosmos has released IOTA, a collaborative distributed pretraining network. Participants contribute compute to collectively pretrain a 15B model. It‚Äôs a model and data parallel setup, meaning people can work on disjointed parts of it at the same time.&lt;/p&gt; &lt;p&gt;It‚Äôs also been designed with a lower barrier to entry, as nobody needs to have a full local copy of the model saved, making it more cost effective to people with smaller setups. The goal is to see if people can pretrain a model in a decentralized setting, producing SOTA-level benchmarks. It‚Äôs a practical investigation into how decentralized and open-source methods can rival centralized LLMs, either now or in the future.&lt;/p&gt; &lt;p&gt;It‚Äôs early days (the project came out about 10 days ago) but they‚Äôve already got a decent number of participants. Plus, there‚Äôs been a nice drop in loss recently.&lt;/p&gt; &lt;p&gt;They‚Äôve got a &lt;a href="https://iota.macrocosmos.ai/dashboard"&gt;real-time 3D dashboard of the model&lt;/a&gt;, showing active participants.&lt;/p&gt; &lt;p&gt;They also published their &lt;a href="https://iota.macrocosmos.ai/research/research.pdf"&gt;technical paper about the architecture&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/emission-control"&gt; /u/emission-control &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9jm52/a_new_swarmstyle_distributed_pretraining/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9jm52/a_new_swarmstyle_distributed_pretraining/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1l9jm52/a_new_swarmstyle_distributed_pretraining/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-06-12T11:02:57+00:00</published>
  </entry>
  <entry>
    <id>t3_1l9n911</id>
    <title>ABBA: Highly Expressive Hadamard Product Adaptation for Large Language Models</title>
    <updated>2025-06-12T14:01:41+00:00</updated>
    <author>
      <name>/u/AccomplishedCode4689</name>
      <uri>https://old.reddit.com/user/AccomplishedCode4689</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;We introduce ABBA, a new architecture for Parameter-Efficient Fine-Tuning (PEFT) that significantly outperforms LoRA and all its major variants across a broad range of benchmarks, all under the same parameter budget.&lt;/p&gt; &lt;p&gt;Most PEFT methods, including LoRA, represent weight updates using a low-rank decomposition added to the frozen model weights. While effective, this structure can limit the expressivity of the update, especially at low rank.&lt;/p&gt; &lt;p&gt;ABBA takes a fundamentally different approach:&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/nta9e7md3i6f1.png?width=446&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=54e090db99fe4694c4b2e9a80778576b0f705169"&gt;ABBA Architecture&lt;/a&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Reparameterizes the update as a Hadamard product of two independently learned low-rank matrices&lt;/li&gt; &lt;li&gt;Decouples the two components of the update from the base model, allowing them to be optimized freely&lt;/li&gt; &lt;li&gt;Enables significantly higher expressivity and improved performance under the same parameter budget&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;üìà Empirical Results&lt;/p&gt; &lt;p&gt;ABBA consistently beats state-of-the-art LoRA-based methods like HiRA, DoRA, and LoRA-Pro across four open-source LLMs: Mistral-7B, Gemma-2 9B, LLaMA-3.2 1B, and LLaMA-3.2 3B, on a suite of commonsense and arithmetic reasoning benchmarks. In several cases, ABBA even outperforms full fine-tuning.&lt;/p&gt; &lt;p&gt;üìÑ Paper: &lt;a href="https://arxiv.org/abs/2505.14238"&gt;https://arxiv.org/abs/2505.14238&lt;/a&gt;&lt;/p&gt; &lt;p&gt;üíª Code: &lt;a href="https://github.com/CERT-Lab/abba"&gt;https://github.com/CERT-Lab/abba&lt;/a&gt;&lt;/p&gt; &lt;p&gt;We‚Äôd love to hear your thoughts, whether you're working on PEFT methods, fine-tuning, or anything related to making LLMs more adaptable and efficient. We're happy to answer questions, discuss implementation details, or just hear how this fits into your work.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/AccomplishedCode4689"&gt; /u/AccomplishedCode4689 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9n911/abba_highly_expressive_hadamard_product/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9n911/abba_highly_expressive_hadamard_product/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1l9n911/abba_highly_expressive_hadamard_product/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-06-12T14:01:41+00:00</published>
  </entry>
  <entry>
    <id>t3_1l9cwi5</id>
    <title>Running an LLM on a PS Vita</title>
    <updated>2025-06-12T03:57:31+00:00</updated>
    <author>
      <name>/u/ajunior7</name>
      <uri>https://old.reddit.com/user/ajunior7</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9cwi5/running_an_llm_on_a_ps_vita/"&gt; &lt;img alt="Running an LLM on a PS Vita" src="https://external-preview.redd.it/MWMwMGd5dnY0ZjZmMdxvYbrJ4twRsyVsSVzosN1N6q8R6lU4U4ntC9uiniMK.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=4f8445568b194107c46a13e005615b84bb24fc2e" title="Running an LLM on a PS Vita" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;After spending some time with my vita I wanted to see if **any** LLM can be ran on it, and it can! I modified llama2.c to have it run on the Vita, with the added capability of downloading the models on device to avoid having to manually transfer model files (which can be deleted too). This was a great way to learn about homebrewing on the Vita, there were a lot of great examples from the VitaSDK team which helped me a lot. If you have a Vita, there is a .vpk compiled in the releases section, check it out!&lt;/p&gt; &lt;p&gt;Repo: &lt;a href="https://github.com/callbacked/psvita-llm"&gt;https://github.com/callbacked/psvita-llm&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/ajunior7"&gt; /u/ajunior7 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/we6m8zvv4f6f1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9cwi5/running_an_llm_on_a_ps_vita/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1l9cwi5/running_an_llm_on_a_ps_vita/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-06-12T03:57:31+00:00</published>
  </entry>
  <entry>
    <id>t3_1l9ghjc</id>
    <title>What happened to Yi?</title>
    <updated>2025-06-12T07:38:46+00:00</updated>
    <author>
      <name>/u/undefdev</name>
      <uri>https://old.reddit.com/user/undefdev</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://huggingface.co/01-ai"&gt;Yi&lt;/a&gt; had some of the best local models in the past, but this year there haven't been any news about them. Does anyone know what happened?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/undefdev"&gt; /u/undefdev &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9ghjc/what_happened_to_yi/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9ghjc/what_happened_to_yi/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1l9ghjc/what_happened_to_yi/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-06-12T07:38:46+00:00</published>
  </entry>
  <entry>
    <id>t3_1l9pwk1</id>
    <title>üßô‚Äç‚ôÇÔ∏è I Built a Local AI Dungeon Master ‚Äì Meet Dungeo_ai (Open Source &amp; Powered by your local LLM )</title>
    <updated>2025-06-12T15:50:26+00:00</updated>
    <author>
      <name>/u/Reasonable_Brief578</name>
      <uri>https://old.reddit.com/user/Reasonable_Brief578</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9pwk1/i_built_a_local_ai_dungeon_master_meet_dungeo_ai/"&gt; &lt;img alt="üßô‚Äç‚ôÇÔ∏è I Built a Local AI Dungeon Master ‚Äì Meet Dungeo_ai (Open Source &amp;amp; Powered by your local LLM )" src="https://external-preview.redd.it/VKXieTbOFzGU2aZe9EDyviI58NBmBHkcxoJcwzIpt0A.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=78f390b5728c07a17be669aafa3632a5c3408b7e" title="üßô‚Äç‚ôÇÔ∏è I Built a Local AI Dungeon Master ‚Äì Meet Dungeo_ai (Open Source &amp;amp; Powered by your local LLM )" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://reddit.com/link/1l9pwk1/video/u4614vthpi6f1/player"&gt;https://reddit.com/link/1l9pwk1/video/u4614vthpi6f1/player&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Hey folks!&lt;/p&gt; &lt;p&gt;I‚Äôve been building something I'm super excited to finally share:&lt;/p&gt; &lt;p&gt;üé≤ Dungeo_ai ‚Äì a fully local, AI-powered Dungeon Master designed for immersive solo RPGs, worldbuilding, and roleplay.&lt;/p&gt; &lt;p&gt;This project it's free and for now it connect to ollama(llm) and alltalktts(tts) &lt;/p&gt; &lt;p&gt;üõ†Ô∏è What it can do:&lt;/p&gt; &lt;p&gt;üíª Runs entirely locally (with support for Ollama )&lt;/p&gt; &lt;p&gt;üß† Persists memory, character state, and custom personalities&lt;/p&gt; &lt;p&gt;üìú Simulates D&amp;amp;D-like dialogue and encounters dynamically&lt;/p&gt; &lt;p&gt;üó∫Ô∏è Expands lore over time with each interaction&lt;/p&gt; &lt;p&gt;üßô Great for solo campaigns, worldbuilding, or even prototyping NPCs&lt;/p&gt; &lt;p&gt;It‚Äôs still early days, but it‚Äôs usable and growing. I‚Äôd love feedback, collab ideas, or even just to know what kind of characters you‚Äôd throw into it.&lt;/p&gt; &lt;p&gt;Here‚Äôs the link again:&lt;/p&gt; &lt;p&gt;üëâ &lt;a href="https://github.com/Laszlobeer/Dungeo_ai/tree/main"&gt;https://github.com/Laszlobeer/Dungeo_ai/tree/main&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Thanks for checking it out‚Äîand if you give it a spin, let me know how your first AI encounter goes. üòÑHey folks!&lt;br /&gt; I‚Äôve been building something I'm super excited to finally share:&lt;br /&gt; üé≤ &lt;a href="https://github.com/Laszlobeer/Dungeo_ai/tree/main"&gt;&lt;strong&gt;Dungeo_ai&lt;/strong&gt;&lt;/a&gt; ‚Äì a fully local, AI-powered Dungeon Master designed for immersive solo RPGs, worldbuilding, and roleplay.&lt;/p&gt; &lt;p&gt;This project it's free and for now it connect to ollama(llm) and alltalktts(tts)&lt;/p&gt; &lt;p&gt;üõ†Ô∏è What it can do:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;üíª Runs entirely &lt;strong&gt;locally&lt;/strong&gt; (with support for Ollama )&lt;/li&gt; &lt;li&gt;üß† Persists memory, character state, and custom personalities&lt;/li&gt; &lt;li&gt;üìú Simulates D&amp;amp;D-like dialogue and encounters dynamically&lt;/li&gt; &lt;li&gt;üó∫Ô∏è Expands lore over time with each interaction&lt;/li&gt; &lt;li&gt;üßô Great for solo campaigns, worldbuilding, or even prototyping NPCs&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;It‚Äôs still early days, but it‚Äôs usable and growing. I‚Äôd love feedback, collab ideas, or even just to know what kind of characters &lt;em&gt;you‚Äôd&lt;/em&gt; throw into it.&lt;/p&gt; &lt;p&gt;Here‚Äôs the link again:&lt;br /&gt; üëâ &lt;a href="https://github.com/Laszlobeer/Dungeo_ai/tree/main"&gt;https://github.com/Laszlobeer/Dungeo_ai/tree/main&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Thanks for checking it out‚Äîand if you give it a spin, let me know how your first AI encounter goes. üòÑ&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Reasonable_Brief578"&gt; /u/Reasonable_Brief578 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9pwk1/i_built_a_local_ai_dungeon_master_meet_dungeo_ai/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9pwk1/i_built_a_local_ai_dungeon_master_meet_dungeo_ai/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1l9pwk1/i_built_a_local_ai_dungeon_master_meet_dungeo_ai/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-06-12T15:50:26+00:00</published>
  </entry>
  <entry>
    <id>t3_1l9ovq7</id>
    <title>Transformer Lab Now Supports Diffusion Model Training in Addition to LLM Training</title>
    <updated>2025-06-12T15:09:03+00:00</updated>
    <author>
      <name>/u/aliasaria</name>
      <uri>https://old.reddit.com/user/aliasaria</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9ovq7/transformer_lab_now_supports_diffusion_model/"&gt; &lt;img alt="Transformer Lab Now Supports Diffusion Model Training in Addition to LLM Training" src="https://preview.redd.it/usk33qqlgi6f1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=4b03743bbc2b1a143d93935a612a5c4512444879" title="Transformer Lab Now Supports Diffusion Model Training in Addition to LLM Training" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;In addition to LLM training and inference, we're excited to have just launched Diffusion Model inference and training. It's all open source! We'd love your feedback and to see what you build.&lt;/p&gt; &lt;p&gt;In the platform we support most major open Diffusion models (including SDXL &amp;amp; Flux). The platform supports inpainting, img2img, and of course LoRA training.&lt;/p&gt; &lt;p&gt;Link to documentation and details here &lt;a href="https://transformerlab.ai/blog/diffusion-support"&gt;https://transformerlab.ai/blog/diffusion-support&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/aliasaria"&gt; /u/aliasaria &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/usk33qqlgi6f1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9ovq7/transformer_lab_now_supports_diffusion_model/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1l9ovq7/transformer_lab_now_supports_diffusion_model/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-06-12T15:09:03+00:00</published>
  </entry>
  <entry>
    <id>t3_1l9rejn</id>
    <title>Qwen3-72B-Embiggened</title>
    <updated>2025-06-12T16:49:08+00:00</updated>
    <author>
      <name>/u/TKGaming_11</name>
      <uri>https://old.reddit.com/user/TKGaming_11</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9rejn/qwen372bembiggened/"&gt; &lt;img alt="Qwen3-72B-Embiggened" src="https://external-preview.redd.it/3jemtoTl3dbvGWwls0qD8rxMoJ2jFMtej9rCleQmntc.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=caeaed61b9102d58a91296d431d16a9370486b24" title="Qwen3-72B-Embiggened" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/TKGaming_11"&gt; /u/TKGaming_11 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://huggingface.co/cognitivecomputations/Qwen3-72B-Embiggened"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9rejn/qwen372bembiggened/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1l9rejn/qwen372bembiggened/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-06-12T16:49:08+00:00</published>
  </entry>
  <entry>
    <id>t3_1l9fec7</id>
    <title>OpenAI delays their open source model claiming to add "something amazing" to it</title>
    <updated>2025-06-12T06:26:23+00:00</updated>
    <author>
      <name>/u/umarmnaq</name>
      <uri>https://old.reddit.com/user/umarmnaq</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9fec7/openai_delays_their_open_source_model_claiming_to/"&gt; &lt;img alt="OpenAI delays their open source model claiming to add &amp;quot;something amazing&amp;quot; to it" src="https://external-preview.redd.it/R_3_vozrpyNLk-RuPK719qfww-pDxCPb4GbyGYYEwIQ.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=35f17ffcf6a5b86edfcd5643785889b2dd77fb23" title="OpenAI delays their open source model claiming to add &amp;quot;something amazing&amp;quot; to it" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/umarmnaq"&gt; /u/umarmnaq &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://techcrunch.com/2025/06/10/openais-open-model-is-delayed"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9fec7/openai_delays_their_open_source_model_claiming_to/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1l9fec7/openai_delays_their_open_source_model_claiming_to/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-06-12T06:26:23+00:00</published>
  </entry>
  <entry>
    <id>t3_1l9hzb5</id>
    <title>Google and Microsoft vs OpenAI and Anthropic, a fun visualization of their open releases on Hugging Face in the past year (Julien Chaumond on LinkedIn)</title>
    <updated>2025-06-12T09:21:44+00:00</updated>
    <author>
      <name>/u/Nunki08</name>
      <uri>https://old.reddit.com/user/Nunki08</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9hzb5/google_and_microsoft_vs_openai_and_anthropic_a/"&gt; &lt;img alt="Google and Microsoft vs OpenAI and Anthropic, a fun visualization of their open releases on Hugging Face in the past year (Julien Chaumond on LinkedIn)" src="https://preview.redd.it/2vdfa3f5sg6f1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=8cc62e350d3b3d31d64be11a8e4372ca1fc5f0e7" title="Google and Microsoft vs OpenAI and Anthropic, a fun visualization of their open releases on Hugging Face in the past year (Julien Chaumond on LinkedIn)" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Nunki08"&gt; /u/Nunki08 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/2vdfa3f5sg6f1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9hzb5/google_and_microsoft_vs_openai_and_anthropic_a/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1l9hzb5/google_and_microsoft_vs_openai_and_anthropic_a/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-06-12T09:21:44+00:00</published>
  </entry>
  <entry>
    <id>t3_1l9p54x</id>
    <title>Nanonets-OCR-s: An Open-Source Image-to-Markdown Model with LaTeX, Tables, Signatures, checkboxes &amp; More</title>
    <updated>2025-06-12T15:19:41+00:00</updated>
    <author>
      <name>/u/SouvikMandal</name>
      <uri>https://old.reddit.com/user/SouvikMandal</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9p54x/nanonetsocrs_an_opensource_imagetomarkdown_model/"&gt; &lt;img alt="Nanonets-OCR-s: An Open-Source Image-to-Markdown Model with LaTeX, Tables, Signatures, checkboxes &amp;amp; More" src="https://external-preview.redd.it/_xcgPKgts5yF5jBIuB89LBBM6G1OD9-qimuRMUyq8jY.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=a45bdc43de827d3d2f41c39e7eb1c65d82e73b20" title="Nanonets-OCR-s: An Open-Source Image-to-Markdown Model with LaTeX, Tables, Signatures, checkboxes &amp;amp; More" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;We're excited to share &lt;strong&gt;Nanonets-OCR-s&lt;/strong&gt;, a powerful and lightweight (3B) VLM model that converts documents into clean, structured &lt;strong&gt;Markdown&lt;/strong&gt;. This model is trained to understand document structure and content context (like tables, equations, images, plots, watermarks, checkboxes, etc.).&lt;/p&gt; &lt;p&gt;üîç &lt;strong&gt;Key Features:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt; &lt;strong&gt;LaTeX Equation Recognition&lt;/strong&gt; Converts inline and block-level math into properly formatted LaTeX, distinguishing between &lt;code&gt;$...$&lt;/code&gt; and &lt;code&gt;$$...$$&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Image Descriptions for LLMs&lt;/strong&gt; Describes embedded images using structured &lt;code&gt;&amp;lt;img&amp;gt;&lt;/code&gt; tags. Handles logos, charts, plots, and so on.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Signature Detection &amp;amp; Isolation&lt;/strong&gt; Finds and tags signatures in scanned documents, outputting them in &lt;code&gt;&amp;lt;signature&amp;gt;&lt;/code&gt; blocks.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Watermark Extraction&lt;/strong&gt; Extracts watermark text and stores it within &lt;code&gt;&amp;lt;watermark&amp;gt;&lt;/code&gt; tag for traceability.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Smart Checkbox &amp;amp; Radio Button Handling&lt;/strong&gt; Converts checkboxes to Unicode symbols like ‚òë, ‚òí, and ‚òê for reliable parsing in downstream apps.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Complex Table Extraction&lt;/strong&gt; Handles multi-row/column tables, preserving structure and outputting both &lt;strong&gt;Markdown&lt;/strong&gt; and &lt;strong&gt;HTML&lt;/strong&gt; formats.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Huggingface / GitHub / Try it out&lt;/strong&gt;:&lt;br /&gt; &lt;a href="https://huggingface.co/nanonets/Nanonets-OCR-s"&gt;Huggingface Model Card&lt;/a&gt;&lt;br /&gt; &lt;a href="https://nanonets.com/research/nanonets-ocr-s/"&gt;Read the full announcement&lt;/a&gt;&lt;br /&gt; &lt;a href="https://github.com/NanoNets/docext/blob/main/PDF2MD_README.md#quickstart"&gt;Try it with Docext in Colab&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/9r53s8oxii6f1.png?width=1762&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5d401151504b45c6c7b7aa49342a2a40bff19a3d"&gt;Document with checkbox and radio buttons&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/ky28mxc1ji6f1.jpg?width=3938&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=0f0ba053a366c0fd0885aea5785b5c040ff590fd"&gt;Document with image&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/yfrazoi3ji6f1.png?width=3640&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4215d426d90f153c5a477f140aa47312e153aab8"&gt;Document with equations&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/am74wtm5ji6f1.jpg?width=1533&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=380788a942ee270cf73ddc7e968773948b4f74f0"&gt;Document with watermark&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/6g80yoj9ji6f1.png?width=3482&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8d6008f9e56e03e7589f38a16ba1917e4e0c419b"&gt;Document with tables&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Feel free to try it out and share your feedback.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/SouvikMandal"&gt; /u/SouvikMandal &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9p54x/nanonetsocrs_an_opensource_imagetomarkdown_model/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9p54x/nanonetsocrs_an_opensource_imagetomarkdown_model/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1l9p54x/nanonetsocrs_an_opensource_imagetomarkdown_model/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-06-12T15:19:41+00:00</published>
  </entry>
  <entry>
    <id>t3_1l9lddr</id>
    <title>Petition: Ban 'announcement of announcement' posts</title>
    <updated>2025-06-12T12:36:45+00:00</updated>
    <author>
      <name>/u/RangaRea</name>
      <uri>https://old.reddit.com/user/RangaRea</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;There's no reason to have 5 posts a week about OpenAI announcing that they will release a model then delaying the release date it then announcing it's gonna be &lt;em&gt;amazing&lt;/em&gt;&lt;strong&gt;‚Ñ¢&lt;/strong&gt; then announcing they will announce a new update in a month ad infinitum. Fuck those grifters.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/RangaRea"&gt; /u/RangaRea &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9lddr/petition_ban_announcement_of_announcement_posts/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1l9lddr/petition_ban_announcement_of_announcement_posts/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1l9lddr/petition_ban_announcement_of_announcement_posts/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-06-12T12:36:45+00:00</published>
  </entry>
</feed>
