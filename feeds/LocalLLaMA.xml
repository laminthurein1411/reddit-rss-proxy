<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>/r/LocalLLaMA/.rss</id>
  <title>LocalLlama</title>
  <updated>2025-01-12T21:34:06+00:00</updated>
  <link href="https://old.reddit.com/r/LocalLLaMA/" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator>
  <icon>https://www.redditstatic.com/icon.png/</icon>
  <subtitle>Subreddit to discuss about Llama, the large language model created by Meta AI.</subtitle>
  <entry>
    <id>t3_1hz2rar</id>
    <title>Why we don't know researchers behind DeepSeek?</title>
    <updated>2025-01-11T18:48:03+00:00</updated>
    <author>
      <name>/u/robertpiosik</name>
      <uri>https://old.reddit.com/user/robertpiosik</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Zero interviews, zero social activity. Zero group photos, none about us page.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/robertpiosik"&gt; /u/robertpiosik &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hz2rar/why_we_dont_know_researchers_behind_deepseek/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hz2rar/why_we_dont_know_researchers_behind_deepseek/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1hz2rar/why_we_dont_know_researchers_behind_deepseek/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-11T18:48:03+00:00</published>
  </entry>
  <entry>
    <id>t3_1hzrgd5</id>
    <title>Are there any use cases for text (non-instruct) models?</title>
    <updated>2025-01-12T17:13:00+00:00</updated>
    <author>
      <name>/u/OneFanFare</name>
      <uri>https://old.reddit.com/user/OneFanFare</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;For example, llama3.2 is available as instruct models, or as text models. I'm wondering if there are any good usecases for the latter? &lt;/p&gt; &lt;p&gt;I remember hearing some people using them for creative writing (start with a sample paragraph and let 'em go) but curious if there's anything else there.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/OneFanFare"&gt; /u/OneFanFare &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzrgd5/are_there_any_use_cases_for_text_noninstruct/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzrgd5/are_there_any_use_cases_for_text_noninstruct/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1hzrgd5/are_there_any_use_cases_for_text_noninstruct/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-12T17:13:00+00:00</published>
  </entry>
  <entry>
    <id>t3_1hzpfwk</id>
    <title>Is there any LLM that is made to teach programming?</title>
    <updated>2025-01-12T15:46:09+00:00</updated>
    <author>
      <name>/u/Comrade_United-World</name>
      <uri>https://old.reddit.com/user/Comrade_United-World</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;If there were any It would be much better, just like I am learning from a dedicated teacher.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Comrade_United-World"&gt; /u/Comrade_United-World &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzpfwk/is_there_any_llm_that_is_made_to_teach_programming/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzpfwk/is_there_any_llm_that_is_made_to_teach_programming/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1hzpfwk/is_there_any_llm_that_is_made_to_teach_programming/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-12T15:46:09+00:00</published>
  </entry>
  <entry>
    <id>t3_1hzqgqm</id>
    <title>How to effectively use AI (Llama) for larger coding projects? Hitting some roadblocks</title>
    <updated>2025-01-12T16:31:03+00:00</updated>
    <author>
      <name>/u/MacDevs</name>
      <uri>https://old.reddit.com/user/MacDevs</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Mobile and web development with AI is incredibly convenient. Even though I have coding knowledge, I now prefer to let AI handle the coding based on my requirements (100%).&lt;/p&gt; &lt;p&gt;I've noticed it's straightforward to create small websites or applications. However, things get more complicated when dealing with multiple files.&lt;/p&gt; &lt;p&gt;First, there's a limit to the number of files we can use. I found a workaround using the Combine Files app on macOS, which allows combining multiple files into a single file.&lt;/p&gt; &lt;p&gt;But then I face a new issue I can't solve: the AI starts removing features without asking (even if I asked not to change the current features). This requires carefully reviewing the submitted code, which is time-consuming.&lt;/p&gt; &lt;p&gt;Have you found any solutions (methods, workflows, prompts) that allow AI to develop projects with over 2000 lines of code?&lt;/p&gt; &lt;p&gt;I'm new to AI development and would appreciate any insights!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/MacDevs"&gt; /u/MacDevs &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzqgqm/how_to_effectively_use_ai_llama_for_larger_coding/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzqgqm/how_to_effectively_use_ai_llama_for_larger_coding/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1hzqgqm/how_to_effectively_use_ai_llama_for_larger_coding/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-12T16:31:03+00:00</published>
  </entry>
  <entry>
    <id>t3_1hzqkkd</id>
    <title>Vector database with LinkedIn Posts plus Engagement Metrics</title>
    <updated>2025-01-12T16:35:45+00:00</updated>
    <author>
      <name>/u/davidmezzetti</name>
      <uri>https://old.reddit.com/user/davidmezzetti</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzqkkd/vector_database_with_linkedin_posts_plus/"&gt; &lt;img alt="Vector database with LinkedIn Posts plus Engagement Metrics" src="https://external-preview.redd.it/1rxY6Io0zblOYmTaFApGbf9v15x7lpEraQqnP6ffWwA.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=07f5f414b66bcd1c1c75a11a1648cffb6fdba754" title="Vector database with LinkedIn Posts plus Engagement Metrics" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/davidmezzetti"&gt; /u/davidmezzetti &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://huggingface.co/NeuML/txtai-neuml-linkedin"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzqkkd/vector_database_with_linkedin_posts_plus/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1hzqkkd/vector_database_with_linkedin_posts_plus/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-12T16:35:45+00:00</published>
  </entry>
  <entry>
    <id>t3_1hzv1v5</id>
    <title>I made a Webui Alternative for Vision Language Models like LLaMA 3.2 11b</title>
    <updated>2025-01-12T19:45:00+00:00</updated>
    <author>
      <name>/u/Any-Shopping2394</name>
      <uri>https://old.reddit.com/user/Any-Shopping2394</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzv1v5/i_made_a_webui_alternative_for_vision_language/"&gt; &lt;img alt=" I made a Webui Alternative for Vision Language Models like LLaMA 3.2 11b " src="https://external-preview.redd.it/reoQFTzGjChcWrotB_NPBBfZ1W2yeo6AUYjnYDwGotU.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=418e01a5c68f28f0ed313d915bf1a6ff4371fec6" title=" I made a Webui Alternative for Vision Language Models like LLaMA 3.2 11b " /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hey, I made this because in the oobabooga text-generation-webui didn't have the capability to use the &amp;quot;multimodal&amp;quot; part of these kind of models (the image sending). It also has characters as you would have them in others webui. It's made using the transformers package.&lt;/p&gt; &lt;p&gt;Tell me what you think about &lt;a href="https://github.com/ricardo2001l/visual-text-generation-webui"&gt;this webui&lt;/a&gt;, also if you want to contribute by making a pull request, i'd be glad. So give it a try &lt;a href="https://github.com/ricardo2001l/visual-text-generation-webui"&gt;https://github.com/ricardo2001l/visual-text-generation-webui&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/9s8wsw3d9mce1.png?width=1902&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=38a388f5479320ed5a2866def64cc7010dfc3637"&gt;how the webui looks&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Any-Shopping2394"&gt; /u/Any-Shopping2394 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzv1v5/i_made_a_webui_alternative_for_vision_language/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzv1v5/i_made_a_webui_alternative_for_vision_language/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1hzv1v5/i_made_a_webui_alternative_for_vision_language/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-12T19:45:00+00:00</published>
  </entry>
  <entry>
    <id>t3_1hze1xk</id>
    <title>6x AMD Instinct Mi60 AI Server vs Llama 405B + vLLM + Open-WebUI - Impressive!</title>
    <updated>2025-01-12T03:48:19+00:00</updated>
    <author>
      <name>/u/Any_Praline_8178</name>
      <uri>https://old.reddit.com/user/Any_Praline_8178</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hze1xk/6x_amd_instinct_mi60_ai_server_vs_llama_405b_vllm/"&gt; &lt;img alt="6x AMD Instinct Mi60 AI Server vs Llama 405B + vLLM + Open-WebUI - Impressive!" src="https://external-preview.redd.it/eDd2Nndjb3ppaGNlMUVpVcA3yZ4wjFwvAE4TdXYq4bpkJwG-QulsV1F4T0eu.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=475a3c9c78a9d27249a2c72bcf664f75b7f9639c" title="6x AMD Instinct Mi60 AI Server vs Llama 405B + vLLM + Open-WebUI - Impressive!" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Any_Praline_8178"&gt; /u/Any_Praline_8178 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/r3w7zbozihce1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hze1xk/6x_amd_instinct_mi60_ai_server_vs_llama_405b_vllm/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1hze1xk/6x_amd_instinct_mi60_ai_server_vs_llama_405b_vllm/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-12T03:48:19+00:00</published>
  </entry>
  <entry>
    <id>t3_1hz7l7d</id>
    <title>OpenAI is losing money , meanwhile qwen is planning voice mode , imagine if they manage to make o1 level model</title>
    <updated>2025-01-11T22:23:27+00:00</updated>
    <author>
      <name>/u/TheLogiqueViper</name>
      <uri>https://old.reddit.com/user/TheLogiqueViper</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hz7l7d/openai_is_losing_money_meanwhile_qwen_is_planning/"&gt; &lt;img alt="OpenAI is losing money , meanwhile qwen is planning voice mode , imagine if they manage to make o1 level model" src="https://preview.redd.it/nhsep8z3xfce1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=c7b460c09bdabd5d02e8e8e46757749c4711b75f" title="OpenAI is losing money , meanwhile qwen is planning voice mode , imagine if they manage to make o1 level model" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/TheLogiqueViper"&gt; /u/TheLogiqueViper &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/nhsep8z3xfce1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hz7l7d/openai_is_losing_money_meanwhile_qwen_is_planning/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1hz7l7d/openai_is_losing_money_meanwhile_qwen_is_planning/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-11T22:23:27+00:00</published>
  </entry>
  <entry>
    <id>t3_1hz5caf</id>
    <title>Tutorial: Run Moondream 2b's new gaze detection on any video</title>
    <updated>2025-01-11T20:42:31+00:00</updated>
    <author>
      <name>/u/ParsaKhaz</name>
      <uri>https://old.reddit.com/user/ParsaKhaz</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hz5caf/tutorial_run_moondream_2bs_new_gaze_detection_on/"&gt; &lt;img alt="Tutorial: Run Moondream 2b's new gaze detection on any video" src="https://external-preview.redd.it/a2VmczhmdHllZmNlMTF40J1mEmizgXzWsZQRgxJwv14NVEzVGBQqF-uixs9J.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=d6d357b58a592f06ed596b1615e185d70bfedfdf" title="Tutorial: Run Moondream 2b's new gaze detection on any video" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/ParsaKhaz"&gt; /u/ParsaKhaz &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/i9ofbftyefce1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hz5caf/tutorial_run_moondream_2bs_new_gaze_detection_on/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1hz5caf/tutorial_run_moondream_2bs_new_gaze_detection_on/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-11T20:42:31+00:00</published>
  </entry>
  <entry>
    <id>t3_1hzvp3n</id>
    <title>API providers that allow grammar-guided sampling?</title>
    <updated>2025-01-12T20:11:51+00:00</updated>
    <author>
      <name>/u/nielsrolf</name>
      <uri>https://old.reddit.com/user/nielsrolf</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I would like to try out deepseek v3 with grammar guided decoding - this is supported by vllm, but I haven't found API providers that expose this feature. Are you aware of any?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/nielsrolf"&gt; /u/nielsrolf &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzvp3n/api_providers_that_allow_grammarguided_sampling/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzvp3n/api_providers_that_allow_grammarguided_sampling/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1hzvp3n/api_providers_that_allow_grammarguided_sampling/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-12T20:11:51+00:00</published>
  </entry>
  <entry>
    <id>t3_1hzd3xs</id>
    <title>Qwen releases Qwen Chat (online)</title>
    <updated>2025-01-12T02:56:09+00:00</updated>
    <author>
      <name>/u/Many_SuchCases</name>
      <uri>https://old.reddit.com/user/Many_SuchCases</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Many_SuchCases"&gt; /u/Many_SuchCases &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://chat.qwenlm.ai"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzd3xs/qwen_releases_qwen_chat_online/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1hzd3xs/qwen_releases_qwen_chat_online/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-12T02:56:09+00:00</published>
  </entry>
  <entry>
    <id>t3_1hzsvr5</id>
    <title>What are the current best low spec LLMs</title>
    <updated>2025-01-12T18:13:22+00:00</updated>
    <author>
      <name>/u/tuxPT</name>
      <uri>https://old.reddit.com/user/tuxPT</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hello.&lt;/p&gt; &lt;p&gt;I'm looking either for advice or a benchmark with the best low spec LLMs. I define low spec as any llm that can run locally in a mobile device or in low spec laptop(integrated GPU+8/12gb ram).&lt;/p&gt; &lt;p&gt;As for tasks, mainly text transformation or questions about the text. No translation needed, the input and output would be in English.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/tuxPT"&gt; /u/tuxPT &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzsvr5/what_are_the_current_best_low_spec_llms/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzsvr5/what_are_the_current_best_low_spec_llms/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1hzsvr5/what_are_the_current_best_low_spec_llms/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-12T18:13:22+00:00</published>
  </entry>
  <entry>
    <id>t3_1hzuouz</id>
    <title>Are you using different model families in your LLM apps/agents for better task performance?</title>
    <updated>2025-01-12T19:29:54+00:00</updated>
    <author>
      <name>/u/AdditionalWeb107</name>
      <uri>https://old.reddit.com/user/AdditionalWeb107</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Anecdotally, I have seen Claude sonet3.5 perform better on structured outputs vs GPT4-o. But conversely see OpenAI model families perform better on other tasks (like creative writing). This experience is amplified for open source models.&lt;/p&gt; &lt;p&gt;So the broader community question is: are you using multiple models from different model families in your apps? If so whatâ€™s your use case and what models are you using?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/AdditionalWeb107"&gt; /u/AdditionalWeb107 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzuouz/are_you_using_different_model_families_in_your/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzuouz/are_you_using_different_model_families_in_your/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1hzuouz/are_you_using_different_model_families_in_your/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-12T19:29:54+00:00</published>
  </entry>
  <entry>
    <id>t3_1hzfjmp</id>
    <title>Parking Systems analysis and Report Generation with Computer vision and Ollama</title>
    <updated>2025-01-12T05:15:40+00:00</updated>
    <author>
      <name>/u/oridnary_artist</name>
      <uri>https://old.reddit.com/user/oridnary_artist</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzfjmp/parking_systems_analysis_and_report_generation/"&gt; &lt;img alt="Parking Systems analysis and Report Generation with Computer vision and Ollama " src="https://external-preview.redd.it/ZDUxcHMwOGt5aGNlMZNdfj6QUni_z9Bf_NJiTzUymfkgPwnfSrss06zjR7A1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=7f892ce79dd89dd0ae0171dc7ac8e70e942f8504" title="Parking Systems analysis and Report Generation with Computer vision and Ollama " /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/oridnary_artist"&gt; /u/oridnary_artist &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/2tf8yz7kyhce1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzfjmp/parking_systems_analysis_and_report_generation/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1hzfjmp/parking_systems_analysis_and_report_generation/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-12T05:15:40+00:00</published>
  </entry>
  <entry>
    <id>t3_1hzsvkz</id>
    <title>Volo: An easy and local way to RAG with Wikipedia!</title>
    <updated>2025-01-12T18:13:08+00:00</updated>
    <author>
      <name>/u/procraftermc</name>
      <uri>https://old.reddit.com/user/procraftermc</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzsvkz/volo_an_easy_and_local_way_to_rag_with_wikipedia/"&gt; &lt;img alt="Volo: An easy and local way to RAG with Wikipedia!" src="https://external-preview.redd.it/fpG2F-y2fJG3IOgvl1H5IK_WS4ZurjXL_2_4lQMcpvY.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=4b4fece65aa394b3776194c084c3d99fcc5693c8" title="Volo: An easy and local way to RAG with Wikipedia!" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;One of the biggest problems with AI models is their tendency to hallucinate. This project aims to fix that by giving them access to an offline copy of Wikipedia (about 57 GB)&lt;/p&gt; &lt;p&gt;It uses a copy of Wikipedia created by Kiwix as the offline database and Qwen2.5:3B as the LLM.&lt;/p&gt; &lt;p&gt;Install instructions are on the Github: &lt;a href="https://github.com/AdyTech99/volo/"&gt;https://github.com/AdyTech99/volo/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/ye31knzzslce1.png?width=3015&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f15216c70371d13352667b4ddce95e3b57e1ffc5"&gt;Example of Volo&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/procraftermc"&gt; /u/procraftermc &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzsvkz/volo_an_easy_and_local_way_to_rag_with_wikipedia/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzsvkz/volo_an_easy_and_local_way_to_rag_with_wikipedia/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1hzsvkz/volo_an_easy_and_local_way_to_rag_with_wikipedia/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-12T18:13:08+00:00</published>
  </entry>
  <entry>
    <id>t3_1hzwun4</id>
    <title>Current best local models for companionship? for random small talk for lonely people</title>
    <updated>2025-01-12T21:01:10+00:00</updated>
    <author>
      <name>/u/MasterScrat</name>
      <uri>https://old.reddit.com/user/MasterScrat</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Asking for a friend.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/MasterScrat"&gt; /u/MasterScrat &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzwun4/current_best_local_models_for_companionship_for/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzwun4/current_best_local_models_for_companionship_for/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1hzwun4/current_best_local_models_for_companionship_for/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-12T21:01:10+00:00</published>
  </entry>
  <entry>
    <id>t3_1hzmljb</id>
    <title>In the Terminator's vision overlay, the "ANALYSIS" is probably the image embedding ðŸ¤”</title>
    <updated>2025-01-12T13:25:15+00:00</updated>
    <author>
      <name>/u/Reddactor</name>
      <uri>https://old.reddit.com/user/Reddactor</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzmljb/in_the_terminators_vision_overlay_the_analysis_is/"&gt; &lt;img alt="In the Terminator's vision overlay, the &amp;quot;ANALYSIS&amp;quot; is probably the image embedding ðŸ¤”" src="https://preview.redd.it/b3if9y5tdkce1.jpeg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=2cdf7470becd28e71636379b90a99d0da4fd0cc3" title="In the Terminator's vision overlay, the &amp;quot;ANALYSIS&amp;quot; is probably the image embedding ðŸ¤”" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Reddactor"&gt; /u/Reddactor &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/b3if9y5tdkce1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzmljb/in_the_terminators_vision_overlay_the_analysis_is/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1hzmljb/in_the_terminators_vision_overlay_the_analysis_is/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-12T13:25:15+00:00</published>
  </entry>
  <entry>
    <id>t3_1hz97my</id>
    <title>they donâ€™t know how good gaze detection is on moondream</title>
    <updated>2025-01-11T23:38:28+00:00</updated>
    <author>
      <name>/u/ParsaKhaz</name>
      <uri>https://old.reddit.com/user/ParsaKhaz</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hz97my/they_dont_know_how_good_gaze_detection_is_on/"&gt; &lt;img alt="they donâ€™t know how good gaze detection is on moondream" src="https://external-preview.redd.it/anBia3RnaGhhZ2NlMSTi0DO1FtxEm4mYFQVOtZR8uuj4lv59wjB_E-Pc4Mjr.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=3206ad0d968f5e06525f4113c574566e35551fb1" title="they donâ€™t know how good gaze detection is on moondream" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/ParsaKhaz"&gt; /u/ParsaKhaz &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/xgysp5nhagce1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hz97my/they_dont_know_how_good_gaze_detection_is_on/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1hz97my/they_dont_know_how_good_gaze_detection_is_on/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-11T23:38:28+00:00</published>
  </entry>
  <entry>
    <id>t3_1hzn5b6</id>
    <title>Forget AI waifus. Are there local AI assistants to increase my productivity?</title>
    <updated>2025-01-12T13:54:45+00:00</updated>
    <author>
      <name>/u/-oshino_shinobu-</name>
      <uri>https://old.reddit.com/user/-oshino_shinobu-</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;As title suggests, lots of lonely men out there looking to fine tune their own AI gf. But I really just want an AI secretary who can help me make plans, trivial tasks like respond to messages/emails, and generally increase my productivity.&lt;/p&gt; &lt;p&gt;What model do you guys suggest? I assume itâ€™ll need huge context length to fit enough data about me? Also hoping thereâ€™s a way to make AI periodically text me and give me updates. I have 48GB of vram to spare for this LLM.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/-oshino_shinobu-"&gt; /u/-oshino_shinobu- &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzn5b6/forget_ai_waifus_are_there_local_ai_assistants_to/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzn5b6/forget_ai_waifus_are_there_local_ai_assistants_to/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1hzn5b6/forget_ai_waifus_are_there_local_ai_assistants_to/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-12T13:54:45+00:00</published>
  </entry>
  <entry>
    <id>t3_1hzany5</id>
    <title>We are an AI company now!</title>
    <updated>2025-01-12T00:47:37+00:00</updated>
    <author>
      <name>/u/Brilliant-Day2748</name>
      <uri>https://old.reddit.com/user/Brilliant-Day2748</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzany5/we_are_an_ai_company_now/"&gt; &lt;img alt="We are an AI company now!" src="https://preview.redd.it/0yl0970umgce1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=53963d0db45722eea8467f27c91ca48e5a7cf6fc" title="We are an AI company now!" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Brilliant-Day2748"&gt; /u/Brilliant-Day2748 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/0yl0970umgce1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzany5/we_are_an_ai_company_now/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1hzany5/we_are_an_ai_company_now/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-12T00:47:37+00:00</published>
  </entry>
  <entry>
    <id>t3_1hz28ld</id>
    <title>Bro whaaaat?</title>
    <updated>2025-01-11T18:24:57+00:00</updated>
    <author>
      <name>/u/Specter_Origin</name>
      <uri>https://old.reddit.com/user/Specter_Origin</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hz28ld/bro_whaaaat/"&gt; &lt;img alt="Bro whaaaat?" src="https://preview.redd.it/cwi5l2ziqece1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=a6895d12163dd294798940a5c5b6368da7f91b2f" title="Bro whaaaat?" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Specter_Origin"&gt; /u/Specter_Origin &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/cwi5l2ziqece1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hz28ld/bro_whaaaat/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1hz28ld/bro_whaaaat/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-11T18:24:57+00:00</published>
  </entry>
  <entry>
    <id>t3_1hzp789</id>
    <title>Mark Zuckerberg believes in 2025, Meta will probably have a mid-level engineer AI that can write code, and over time it will replace people engineers.</title>
    <updated>2025-01-12T15:34:50+00:00</updated>
    <author>
      <name>/u/Admirable-Star7088</name>
      <uri>https://old.reddit.com/user/Admirable-Star7088</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://x.com/slow_developer/status/1877798620692422835?mx=2"&gt;https://x.com/slow_developer/status/1877798620692422835?mx=2&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=USBW0ESLEK0"&gt;https://www.youtube.com/watch?v=USBW0ESLEK0&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://tribune.com.pk/story/2521499/zuckerberg-announces-meta-plans-to-replace-mid-level-engineers-with-ais-this-year"&gt;https://tribune.com.pk/story/2521499/zuckerberg-announces-meta-plans-to-replace-mid-level-engineers-with-ais-this-year&lt;/a&gt;&lt;/p&gt; &lt;p&gt;What do you think, is he a bit too optimistic here, or should we expect greatly improved (coding) LLMs very soon? Will this be Llama 4? :D&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Admirable-Star7088"&gt; /u/Admirable-Star7088 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzp789/mark_zuckerberg_believes_in_2025_meta_will/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzp789/mark_zuckerberg_believes_in_2025_meta_will/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1hzp789/mark_zuckerberg_believes_in_2025_meta_will/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-12T15:34:50+00:00</published>
  </entry>
  <entry>
    <id>t3_1hzuw4z</id>
    <title>Kokoro #1 on TTS leaderboard</title>
    <updated>2025-01-12T19:38:14+00:00</updated>
    <author>
      <name>/u/DeltaSqueezer</name>
      <uri>https://old.reddit.com/user/DeltaSqueezer</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;After a short time and a few sabotage attempts, Kokoro is now #1 on the TTS Arena Leaderboard:&lt;/p&gt; &lt;p&gt;&lt;a href="https://huggingface.co/spaces/Pendrokar/TTS-Spaces-Arena"&gt;https://huggingface.co/spaces/Pendrokar/TTS-Spaces-Arena&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I hadn't done any comparative tests to see whether it was better than XTTSv2 (which I was using previously) but the smaller model size and licensing was enough for me to switch after using it just for a few minutes.&lt;/p&gt; &lt;p&gt;I'd like to see work do produce a F16 and Int8 version (currently, I'm running the full F32 version). But this is a very nice model in terms of size performance when you just need simple TTS rendering of text.&lt;/p&gt; &lt;p&gt;I guess the author is busy developing, but I'd love to see a paper on this to understand how the model size was chosen and whether even smaller model sizes were explored.&lt;/p&gt; &lt;p&gt;It would be nice eventually if the full training pipeline and training data would also be open sourced to allow for reproduction, but even having the current voices and model is already very nice.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/DeltaSqueezer"&gt; /u/DeltaSqueezer &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzuw4z/kokoro_1_on_tts_leaderboard/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzuw4z/kokoro_1_on_tts_leaderboard/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1hzuw4z/kokoro_1_on_tts_leaderboard/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-12T19:38:14+00:00</published>
  </entry>
  <entry>
    <id>t3_1hzkw3f</id>
    <title>DeepSeek V3 is the gift that keeps on giving!</title>
    <updated>2025-01-12T11:37:25+00:00</updated>
    <author>
      <name>/u/indicava</name>
      <uri>https://old.reddit.com/user/indicava</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzkw3f/deepseek_v3_is_the_gift_that_keeps_on_giving/"&gt; &lt;img alt="DeepSeek V3 is the gift that keeps on giving!" src="https://preview.redd.it/fj10nizoujce1.png?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=8b294748a76dfcaf7f0f25300479cd3ea3b25308" title="DeepSeek V3 is the gift that keeps on giving!" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/indicava"&gt; /u/indicava &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/fj10nizoujce1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzkw3f/deepseek_v3_is_the_gift_that_keeps_on_giving/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1hzkw3f/deepseek_v3_is_the_gift_that_keeps_on_giving/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-12T11:37:25+00:00</published>
  </entry>
  <entry>
    <id>t3_1hzmpuq</id>
    <title>VLC to add offline, real-time AI subtitles. What do you think the tech stack for this is?</title>
    <updated>2025-01-12T13:31:43+00:00</updated>
    <author>
      <name>/u/SpudMonkApe</name>
      <uri>https://old.reddit.com/user/SpudMonkApe</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzmpuq/vlc_to_add_offline_realtime_ai_subtitles_what_do/"&gt; &lt;img alt="VLC to add offline, real-time AI subtitles. What do you think the tech stack for this is?" src="https://external-preview.redd.it/aphKSMbfvfDHStraL4JSGgDfke__oze-3mdG_k4jOVQ.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=37b50e3ca1b1a72567f853cc77c80c80b325c53a" title="VLC to add offline, real-time AI subtitles. What do you think the tech stack for this is?" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/SpudMonkApe"&gt; /u/SpudMonkApe &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://www.pcmag.com/news/vlc-media-player-to-use-ai-to-generate-subtitles-for-videos"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1hzmpuq/vlc_to_add_offline_realtime_ai_subtitles_what_do/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1hzmpuq/vlc_to_add_offline_realtime_ai_subtitles_what_do/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-01-12T13:31:43+00:00</published>
  </entry>
</feed>
