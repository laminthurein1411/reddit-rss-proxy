<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>/r/LocalLLaMA/.rss</id>
  <title>LocalLlama</title>
  <updated>2025-03-24T19:48:55+00:00</updated>
  <link href="https://old.reddit.com/r/LocalLLaMA/" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator>
  <icon>https://www.redditstatic.com/icon.png/</icon>
  <subtitle>Subreddit to discuss about Llama, the large language model created by Meta AI.</subtitle>
  <entry>
    <id>t3_1jiilot</id>
    <title>jukofyork/DeepSeek-R1-DRAFT-0.5B-GGUF ¬∑ Hugging Face</title>
    <updated>2025-03-24T04:24:30+00:00</updated>
    <author>
      <name>/u/Aaaaaaaaaeeeee</name>
      <uri>https://old.reddit.com/user/Aaaaaaaaaeeeee</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jiilot/jukofyorkdeepseekr1draft05bgguf_hugging_face/"&gt; &lt;img alt="jukofyork/DeepSeek-R1-DRAFT-0.5B-GGUF ¬∑ Hugging Face" src="https://external-preview.redd.it/s10KkW_R4qMdLDisGcqbfEBZS2Ye7-xQcXtqJrlwkdQ.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=3e1d39d630b0703ef51c2c41d065cb21b81b2ceb" title="jukofyork/DeepSeek-R1-DRAFT-0.5B-GGUF ¬∑ Hugging Face" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Aaaaaaaaaeeeee"&gt; /u/Aaaaaaaaaeeeee &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://huggingface.co/jukofyork/DeepSeek-R1-DRAFT-0.5B-GGUF"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jiilot/jukofyorkdeepseekr1draft05bgguf_hugging_face/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jiilot/jukofyorkdeepseekr1draft05bgguf_hugging_face/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T04:24:30+00:00</published>
  </entry>
  <entry>
    <id>t3_1jie6oo</id>
    <title>Mistral small draft model</title>
    <updated>2025-03-24T00:27:09+00:00</updated>
    <author>
      <name>/u/frivolousfidget</name>
      <uri>https://old.reddit.com/user/frivolousfidget</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jie6oo/mistral_small_draft_model/"&gt; &lt;img alt="Mistral small draft model" src="https://external-preview.redd.it/fGQq4SyEYUq9b_wFHpxbLnoYjtgYQA70SDrLvYPMmkg.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=6c1cb6b0de0e00a235e6f56fd99854ec7f7e0180" title="Mistral small draft model" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I was browsing hugging face and found this model, made a 4bit mlx quants and it actually seems to work really well! 60.7% accepted tokens in a coding test!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/frivolousfidget"&gt; /u/frivolousfidget &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://huggingface.co/alamios/Mistral-Small-3.1-DRAFT-0.5B"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jie6oo/mistral_small_draft_model/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jie6oo/mistral_small_draft_model/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T00:27:09+00:00</published>
  </entry>
  <entry>
    <id>t3_1jiv80d</id>
    <title>Awesome-MCP-List: I gathered and created a good collection of MCP server for using in ollama , cursor and cline.</title>
    <updated>2025-03-24T16:42:45+00:00</updated>
    <author>
      <name>/u/Different-Olive-8745</name>
      <uri>https://old.reddit.com/user/Different-Olive-8745</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;(&lt;a href="https://github.com/MobinX/awesome-mcp-list"&gt;https://github.com/MobinX/awesome-mcp-list&lt;/a&gt;)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Different-Olive-8745"&gt; /u/Different-Olive-8745 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jiv80d/awesomemcplist_i_gathered_and_created_a_good/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jiv80d/awesomemcplist_i_gathered_and_created_a_good/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jiv80d/awesomemcplist_i_gathered_and_created_a_good/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T16:42:45+00:00</published>
  </entry>
  <entry>
    <id>t3_1ji525h</id>
    <title>Since its release I've gone through all three phases of QwQ acceptance</title>
    <updated>2025-03-23T17:47:23+00:00</updated>
    <author>
      <name>/u/ForsookComparison</name>
      <uri>https://old.reddit.com/user/ForsookComparison</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ji525h/since_its_release_ive_gone_through_all_three/"&gt; &lt;img alt="Since its release I've gone through all three phases of QwQ acceptance" src="https://preview.redd.it/8qv1c0xd8hqe1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=61fdacdcc23fd66a96010f24d3c0bec601ad7eed" title="Since its release I've gone through all three phases of QwQ acceptance" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/ForsookComparison"&gt; /u/ForsookComparison &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/8qv1c0xd8hqe1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1ji525h/since_its_release_ive_gone_through_all_three/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1ji525h/since_its_release_ive_gone_through_all_three/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-23T17:47:23+00:00</published>
  </entry>
  <entry>
    <id>t3_1jivc1w</id>
    <title>That 80s album cover... [prompt challenge]</title>
    <updated>2025-03-24T16:47:17+00:00</updated>
    <author>
      <name>/u/dpedley</name>
      <uri>https://old.reddit.com/user/dpedley</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jivc1w/that_80s_album_cover_prompt_challenge/"&gt; &lt;img alt="That 80s album cover... [prompt challenge]" src="https://external-preview.redd.it/XQf5yPW-fDp8-jX9Rrw-Pek-npevjmrKkl3X_q3bf2o.jpg?width=216&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=0eeca9cb0c23b15975c41e713efb1087722a4083" title="That 80s album cover... [prompt challenge]" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I have been using this prompt as a test for LLMs, thought I'd share here - &lt;/p&gt; &lt;p&gt;&lt;code&gt;I'm looking to create a simple web page. I have the html / css, and would like you to create the javascript that renders something that like the 1980s Joy Division album cover for Unknown Pleasures. You can assume I have the HTML and CSS already complete, and a canvas named &amp;quot;albumcover&amp;quot;. Please add comments to the javascript to explain the various parts.&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Unknown_Pleasures"&gt;wikipedia entry&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I sometimes add more about the source to the description:&lt;/p&gt; &lt;p&gt;&lt;code&gt;The image used on the cover is based on an image of radio waves from from a pulsar.&lt;/code&gt;&lt;/p&gt; &lt;p&gt;It's a challenging prompt for most LLMs, I'd be curious to see results from the different LLMs you use.&lt;/p&gt; &lt;p&gt;[edit some formatting]&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/5xvi4tng2oqe1.png?width=2941&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=59028f7b89bad8458ec5defdb574eac30c288be8"&gt;ChatGPT Joy Division, multiple refinements.&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/dpedley"&gt; /u/dpedley &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jivc1w/that_80s_album_cover_prompt_challenge/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jivc1w/that_80s_album_cover_prompt_challenge/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jivc1w/that_80s_album_cover_prompt_challenge/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T16:47:17+00:00</published>
  </entry>
  <entry>
    <id>t3_1jiewjn</id>
    <title>Possible Llama 4 prototypes on Chatbot Arena</title>
    <updated>2025-03-24T01:02:40+00:00</updated>
    <author>
      <name>/u/brown2green</name>
      <uri>https://old.reddit.com/user/brown2green</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;There currently is an unusually large number of anonymous Llama/Meta models randomly appearing on &lt;a href="https://lmarena.ai/"&gt;Chatbot Arena&lt;/a&gt; Battle and it's fair to assume assuming that all or most of them are test versions of Llama 4. Most appear to have image input capabilities and some have a different feel than others. Anybody tested them?&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;aurora&lt;/code&gt; -&amp;gt; Developed by MetaAI, image-enabled.&lt;/li&gt; &lt;li&gt;&lt;code&gt;ertiga&lt;/code&gt; -&amp;gt; Llama, developed by MetaAI, image-enabled.&lt;/li&gt; &lt;li&gt;&lt;code&gt;pinnacle&lt;/code&gt; -&amp;gt; Llama, developed by MetaAI, image-enabled.&lt;/li&gt; &lt;li&gt;&lt;code&gt;rhea&lt;/code&gt; -&amp;gt; Claims to be Llama 3, a friendly assistant created by Meta AI.&lt;/li&gt; &lt;li&gt;&lt;code&gt;solaris&lt;/code&gt; -&amp;gt; Llama model, image-enabled.&lt;/li&gt; &lt;li&gt;&lt;code&gt;sparrow&lt;/code&gt; -&amp;gt; LLaMA (Large Language Model Application), made by Meta&lt;/li&gt; &lt;li&gt;&lt;code&gt;spectra&lt;/code&gt; -&amp;gt; No name disclosed, but created by MetaAI. Image-enabled.&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/brown2green"&gt; /u/brown2green &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jiewjn/possible_llama_4_prototypes_on_chatbot_arena/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jiewjn/possible_llama_4_prototypes_on_chatbot_arena/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jiewjn/possible_llama_4_prototypes_on_chatbot_arena/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T01:02:40+00:00</published>
  </entry>
  <entry>
    <id>t3_1jilv1g</id>
    <title>Experimental Support for GPU (Vulkan) in Distributed Llama</title>
    <updated>2025-03-24T08:23:10+00:00</updated>
    <author>
      <name>/u/b4rtaz</name>
      <uri>https://old.reddit.com/user/b4rtaz</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jilv1g/experimental_support_for_gpu_vulkan_in/"&gt; &lt;img alt="Experimental Support for GPU (Vulkan) in Distributed Llama" src="https://external-preview.redd.it/r8ksxQA0c7npTwIVOsKGIuivjE_pYt6Knh2HhI9gds4.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=2fee55aba182e87af585c45a0193224135c7fd30" title="Experimental Support for GPU (Vulkan) in Distributed Llama" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/b4rtaz"&gt; /u/b4rtaz &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://github.com/b4rtaz/distributed-llama/releases/tag/v0.13.0"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jilv1g/experimental_support_for_gpu_vulkan_in/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jilv1g/experimental_support_for_gpu_vulkan_in/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T08:23:10+00:00</published>
  </entry>
  <entry>
    <id>t3_1jiu2ek</id>
    <title>What inference speed are you getting with dual 3090s on 32B/70B models?</title>
    <updated>2025-03-24T15:56:14+00:00</updated>
    <author>
      <name>/u/1BlueSpork</name>
      <uri>https://old.reddit.com/user/1BlueSpork</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I'm getting around 30 T/s on 32B models and about 1 T/s on 70B with a single 3090. I'm considering upgrading to dual 3090s but don't know if the speed boost justifies the cost and effort. If you‚Äôve run 32B or 70B on dual 3090s, what speeds are you seeing? EDIT: I'm using llama.cpp or Ollama and mostly Q4, and I'm also interested in opitons to improve the speed withouth upgrading to dual 3090.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/1BlueSpork"&gt; /u/1BlueSpork &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jiu2ek/what_inference_speed_are_you_getting_with_dual/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jiu2ek/what_inference_speed_are_you_getting_with_dual/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jiu2ek/what_inference_speed_are_you_getting_with_dual/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T15:56:14+00:00</published>
  </entry>
  <entry>
    <id>t3_1jijga9</id>
    <title>FanFic-Illustrator: A 3B Reasoning Model that Transforms Your Stories into Perfect Illustration Prompts</title>
    <updated>2025-03-24T05:20:23+00:00</updated>
    <author>
      <name>/u/dahara111</name>
      <uri>https://old.reddit.com/user/dahara111</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I'm excited to share FanFic-Illustrator, a specialized 3B reasoning model that bridges creative writing and AI image generation. This model analyzes your stories (original or fan fiction) and suggests optimal illustration scenes with perfectly crafted prompts for image generation models.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;What makes FanFic-Illustrator special:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Converts narrative text into optimized Danbooru tags for image generation (particularly tuned for [animagine-xl-4.0 opt](&lt;a href="https://huggingface.co/cagliostrolab/animagine-xl-4.0"&gt;https://huggingface.co/cagliostrolab/animagine-xl-4.0&lt;/a&gt;)&lt;/li&gt; &lt;li&gt;Shows its reasoning process so you understand why certain scenes and elements were chosen&lt;/li&gt; &lt;li&gt;Supports multilingual input (primarily Japanese, with good handling of English and Chinese)&lt;/li&gt; &lt;li&gt;Allows control over output category/tendency by specifying content categories and providing prioritized tag sets&lt;/li&gt; &lt;li&gt;Lightweight at just 3B parameters, based on Qwen2.5-3B-Instruct&lt;/li&gt; &lt;li&gt;Trained using Unsloth (GPTO) for efficient reinforcement learning.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;FanFic-Illustrator bridges an important gap in the AI creative pipeline - Danbooru tags (special terms like &amp;quot;1girl&amp;quot;, &amp;quot;solo&amp;quot;, &amp;quot;looking at viewer&amp;quot;, etc.) are widely used in open-weight image generation AI but can be challenging for newcomers to master. This model handles the complexity for you, converting natural language stories into effective prompt structures.&lt;/p&gt; &lt;p&gt;I expect this to create powerful synergies with creative writing LLMs, allowing for end-to-end story-to-illustration workflows.&lt;/p&gt; &lt;p&gt;model&lt;br /&gt; &lt;a href="https://huggingface.co/webbigdata/FanFic-Illustrator"&gt;https://huggingface.co/webbigdata/FanFic-Illustrator&lt;/a&gt;&lt;/p&gt; &lt;p&gt;gguf model with sample script&lt;br /&gt; &lt;a href="https://huggingface.co/webbigdata/FanFic-Illustrator_gguf"&gt;https://huggingface.co/webbigdata/FanFic-Illustrator_gguf&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Free Colab sample&lt;br /&gt; &lt;a href="https://github.com/webbigdata-jp/python_sample/blob/main/FanFic_Illustrator_demo.ipynb"&gt;https://github.com/webbigdata-jp/python_sample/blob/main/FanFic_Illustrator_demo.ipynb&lt;/a&gt;&lt;/p&gt; &lt;p&gt;This first release is fully open-source under the Apache-2.0 license. I created it because I thought it would be technically interesting and fill a genuine need. While I'm primarily sharing it with the community to see how people use it and gather feedback for improvements, I'm also curious about potential applications people might discover. If you find innovative ways to use this in your projects or workflows, I'd love to hear about them!&lt;/p&gt; &lt;p&gt;During development, I discovered that creative text-to-illustration conversion tools like this lack established benchmarks, making objective evaluation particularly challenging. To accurately measure user experience and output quality, we may need to build entirely new evaluation criteria and testing methodologies. This challenge extends beyond technical issues, as the very definition of a 'good illustration suggestion' is inherently subjective. Community feedback will be invaluable in overcoming these hurdles and guiding future improvements.&lt;/p&gt; &lt;p&gt;Thank you.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/dahara111"&gt; /u/dahara111 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jijga9/fanficillustrator_a_3b_reasoning_model_that/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jijga9/fanficillustrator_a_3b_reasoning_model_that/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jijga9/fanficillustrator_a_3b_reasoning_model_that/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T05:20:23+00:00</published>
  </entry>
  <entry>
    <id>t3_1jioxgl</id>
    <title>DeepSeek V3 Minor Update?</title>
    <updated>2025-03-24T11:59:33+00:00</updated>
    <author>
      <name>/u/Cheap_Ship6400</name>
      <uri>https://old.reddit.com/user/Cheap_Ship6400</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jioxgl/deepseek_v3_minor_update/"&gt; &lt;img alt="DeepSeek V3 Minor Update?" src="https://b.thumbs.redditmedia.com/c_od9mincjeFa1u5CXICmGv0ARkit1y9Wm_rKGsXsvQ.jpg" title="DeepSeek V3 Minor Update?" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://preview.redd.it/zuoj2qhllmqe1.png?width=1290&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=281e75adeeaf43d451216ce83d12503601cd9b2a"&gt;https://preview.redd.it/zuoj2qhllmqe1.png?width=1290&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=281e75adeeaf43d451216ce83d12503601cd9b2a&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Translation of the image:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;DeepSeek Assistant @ DeepSeek: (DeepSeek's official bot)&lt;/p&gt; &lt;p&gt;„ÄêAnnouncement„ÄëThe DeepSeek V3 model has completed a minor version upgrade. You are welcome to try it out on the official website, app, or mini-program (with Deep Thinking disabled). The API interface and usage methods remain unchanged.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;My experience:&lt;/strong&gt; &lt;/p&gt; &lt;p&gt;It's giving me major DeepSeek R1 vibes. The output's way more unpredictable, plus throwing in fancy emojis. Futhermore, it seems like new V3 is more like Claude when it comes to code and whipping up SVGs.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Cheap_Ship6400"&gt; /u/Cheap_Ship6400 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jioxgl/deepseek_v3_minor_update/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jioxgl/deepseek_v3_minor_update/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jioxgl/deepseek_v3_minor_update/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T11:59:33+00:00</published>
  </entry>
  <entry>
    <id>t3_1jifvny</id>
    <title>I made a diagram and explanation of how transformers work</title>
    <updated>2025-03-24T01:52:51+00:00</updated>
    <author>
      <name>/u/Cromulent123</name>
      <uri>https://old.reddit.com/user/Cromulent123</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jifvny/i_made_a_diagram_and_explanation_of_how/"&gt; &lt;img alt="I made a diagram and explanation of how transformers work" src="https://b.thumbs.redditmedia.com/fprSteMLUKc-khfg243EAMYIKDnFkQHn_2xMr_C2w7o.jpg" title="I made a diagram and explanation of how transformers work" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Cromulent123"&gt; /u/Cromulent123 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://www.reddit.com/gallery/1jifvny"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jifvny/i_made_a_diagram_and_explanation_of_how/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jifvny/i_made_a_diagram_and_explanation_of_how/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T01:52:51+00:00</published>
  </entry>
  <entry>
    <id>t3_1jiljpe</id>
    <title>MSI again teases GeForce RTX 5080 with 24GB memory</title>
    <updated>2025-03-24T07:57:54+00:00</updated>
    <author>
      <name>/u/regunakyle</name>
      <uri>https://old.reddit.com/user/regunakyle</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jiljpe/msi_again_teases_geforce_rtx_5080_with_24gb_memory/"&gt; &lt;img alt="MSI again teases GeForce RTX 5080 with 24GB memory" src="https://external-preview.redd.it/5BWhRWZ8DGaRwq5UYh8SMDqb1b2NpYJnFNdVg0eHXd4.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=523d28119527a66cb2d6ee26c55fae8708a7c6bf" title="MSI again teases GeForce RTX 5080 with 24GB memory" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/regunakyle"&gt; /u/regunakyle &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://videocardz.com/newz/msi-again-teases-geforce-rtx-5080-with-24gb-memory"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jiljpe/msi_again_teases_geforce_rtx_5080_with_24gb_memory/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jiljpe/msi_again_teases_geforce_rtx_5080_with_24gb_memory/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T07:57:54+00:00</published>
  </entry>
  <entry>
    <id>t3_1jinm8p</id>
    <title>I took your guys advice and made a React Reasoning UI model! It has a new reasoning structure and uses state, for component generation! TESSA-T1 (on Huggingface, from the creator of UIGEN)</title>
    <updated>2025-03-24T10:37:08+00:00</updated>
    <author>
      <name>/u/United-Rush4073</name>
      <uri>https://old.reddit.com/user/United-Rush4073</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jinm8p/i_took_your_guys_advice_and_made_a_react/"&gt; &lt;img alt="I took your guys advice and made a React Reasoning UI model! It has a new reasoning structure and uses state, for component generation! TESSA-T1 (on Huggingface, from the creator of UIGEN)" src="https://external-preview.redd.it/aHhhb2FrcWQ1bXFlMRJZCnWIqpqA-PWEKDHLhCPlKPFJgchtistQtNSdyEex.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=22a548c77157d133a621e7c05b10b3d59179dee1" title="I took your guys advice and made a React Reasoning UI model! It has a new reasoning structure and uses state, for component generation! TESSA-T1 (on Huggingface, from the creator of UIGEN)" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hey! Thanks to you guys a few weeks ago, my UIGEN models were trending on HF, with over 15k+ downloads. Because of that, I had a lot of very nice people reach out to me, offering free compute and resources. So I was able to make a better model!&lt;/p&gt; &lt;p&gt;&lt;a href="https://huggingface.co/Tesslate/Tessa-T1-14B"&gt;Tessa-T1-14B&lt;/a&gt; is a reasoning model built on Qwen2.5 Coder. You can find all the size variants here: &lt;a href="https://huggingface.co/collections/Tesslate/tessa-t1-react-reasoning-model-67e0fb72ca23e04473885c0e"&gt;(32B, 14B, 7B, 3B)&lt;/a&gt;. It follows State, useref, useffect and a lot of react libraries like router. In the upcoming weeks I'll be releasing with shadcn. This model can be used in a multi-agent system to generate components or pages and make them work together.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The reasoning comes from a custom finetuned model but is more geared towards UI generation. You can tell this by how it backtracks and thinks about different design principles as the thought process. (Gestalt, etc)&lt;/li&gt; &lt;li&gt;The reasoning bounces between code and not code, and tries its best to check itself before generating.&lt;/li&gt; &lt;li&gt;For those who need it: &lt;a href="https://huggingface.co/Tesslate/Tessa-T1-14B-Q8_0-GGUF"&gt;GGUF&lt;/a&gt;&lt;/li&gt; &lt;li&gt;I had a lot of fun with this model. Just playing around with it and experimenting was really fun and unexpected.&lt;/li&gt; &lt;li&gt;Its very sensitive to temperature and chat template. I recommend the default parameters in LMSTUDIO.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Not just that, I'm also launching an update to &lt;a href="https://huggingface.co/collections/Tesslate/uigen-t15-reasoning-model-67e0fc3605add0af7c427c75"&gt;UIGEN-T1.5&lt;/a&gt;! Its a UI reasoning model that generates html css js tailwind, but I've upgraded the graphics a little bit. (You can check the model card for examples). This is part of my new model training pipeline (which will be available to the public once ready) where I can get data from unstructured sources and use it to create reasoning.&lt;/p&gt; &lt;p&gt;As always, I‚Äôd love to hear your feedback and see how you‚Äôre using it. Happy experimenting! (real question is can someone make a spinning balls demo on this).&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/United-Rush4073"&gt; /u/United-Rush4073 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/idvt1kqd5mqe1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jinm8p/i_took_your_guys_advice_and_made_a_react/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jinm8p/i_took_your_guys_advice_and_made_a_react/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T10:37:08+00:00</published>
  </entry>
  <entry>
    <id>t3_1jiook5</id>
    <title>LLMs on a Steam Deck in Docker</title>
    <updated>2025-03-24T11:45:14+00:00</updated>
    <author>
      <name>/u/Everlier</name>
      <uri>https://old.reddit.com/user/Everlier</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jiook5/llms_on_a_steam_deck_in_docker/"&gt; &lt;img alt="LLMs on a Steam Deck in Docker" src="https://external-preview.redd.it/cHhsYnZ6bnVrbXFlMWk0BDd4-QDMiZx1kTrcST9W7IN4hLEz2IEbJGuZDar2.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=8c9af1e809a2ed2bd77854137b66776def0b0e69" title="LLMs on a Steam Deck in Docker" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Everlier"&gt; /u/Everlier &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/vdpn00oukmqe1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jiook5/llms_on_a_steam_deck_in_docker/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jiook5/llms_on_a_steam_deck_in_docker/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T11:45:14+00:00</published>
  </entry>
  <entry>
    <id>t3_1jijyx2</id>
    <title>I don't understand what an LLM exactly is anymore</title>
    <updated>2025-03-24T05:57:34+00:00</updated>
    <author>
      <name>/u/surveypoodle</name>
      <uri>https://old.reddit.com/user/surveypoodle</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;About a year ago when LLMs were kind of new, the most intuitive explanation I found was that it is predicting the next word or token, appending that to the input and repeating, and that the prediction itself is based on pretrainedf weights which comes from large amount of texts.&lt;/p&gt; &lt;p&gt;Now I'm seeing audio generation, image generation, image classification, segmentation and all kinds of things also under LLMs so I'm not sure what exactly is going on. Did an LLM suddenly become more generalized?&lt;/p&gt; &lt;p&gt;As an example, [SpatialLM](&lt;a href="https://manycore-research.github.io/SpatialLM/"&gt;https://manycore-research.github.io/SpatialLM/&lt;/a&gt;) says it processes 3D point cloud data and understands 3D scenes. I don't understand what this has anything to do with language models.&lt;/p&gt; &lt;p&gt;Can someone explain?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/surveypoodle"&gt; /u/surveypoodle &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jijyx2/i_dont_understand_what_an_llm_exactly_is_anymore/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jijyx2/i_dont_understand_what_an_llm_exactly_is_anymore/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jijyx2/i_dont_understand_what_an_llm_exactly_is_anymore/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T05:57:34+00:00</published>
  </entry>
  <entry>
    <id>t3_1jig5re</id>
    <title>Meta released a paper last month that seems to have gone under the radar. ParetoQ: Scaling Laws in Extremely Low-bit LLM Quantization. This is a better solution than BitNet and means if Meta wanted (for 10% extra compute) they could give us extremely performant 2-bit models.</title>
    <updated>2025-03-24T02:07:26+00:00</updated>
    <author>
      <name>/u/jd_3d</name>
      <uri>https://old.reddit.com/user/jd_3d</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jig5re/meta_released_a_paper_last_month_that_seems_to/"&gt; &lt;img alt="Meta released a paper last month that seems to have gone under the radar. ParetoQ: Scaling Laws in Extremely Low-bit LLM Quantization. This is a better solution than BitNet and means if Meta wanted (for 10% extra compute) they could give us extremely performant 2-bit models." src="https://b.thumbs.redditmedia.com/9hRP5bjRzlFUKNIF0QROoq6Vx5TN7YGbabV11IZeJ3M.jpg" title="Meta released a paper last month that seems to have gone under the radar. ParetoQ: Scaling Laws in Extremely Low-bit LLM Quantization. This is a better solution than BitNet and means if Meta wanted (for 10% extra compute) they could give us extremely performant 2-bit models." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/jd_3d"&gt; /u/jd_3d &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://arxiv.org/pdf/2502.02631"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jig5re/meta_released_a_paper_last_month_that_seems_to/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jig5re/meta_released_a_paper_last_month_that_seems_to/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T02:07:26+00:00</published>
  </entry>
  <entry>
    <id>t3_1jiwadm</id>
    <title>Think Tool Boosts Accuracy by 54%! (+ Ollama integration)</title>
    <updated>2025-03-24T17:24:38+00:00</updated>
    <author>
      <name>/u/Straight-Worker-4327</name>
      <uri>https://old.reddit.com/user/Straight-Worker-4327</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Anthropic just dropped a &lt;strong&gt;game-changer&lt;/strong&gt; for AI problem-solving: Claude‚Äôs new &lt;em&gt;‚Äúthink‚Äù tool&lt;/em&gt; acts like a mental scratchpad, letting the AI pause mid-task to analyze data, verify policies, and avoid costly mistakes.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Key results from their benchmarks:&lt;/strong&gt;&lt;br /&gt; ‚úÖ &lt;strong&gt;54% accuracy boost&lt;/strong&gt; in airline customer service tasks&lt;br /&gt; ‚úÖ &lt;strong&gt;20%+ consistency gains&lt;/strong&gt; in multi-step workflows&lt;br /&gt; ‚úÖ &lt;strong&gt;State-of-the-art coding performance&lt;/strong&gt; (0.623 SWE-Bench score)&lt;/p&gt; &lt;p&gt;I made a &lt;a href="https://www.youtube.com/watch?v=h_c5nVYFyIE"&gt;&lt;strong&gt;video breakdown&lt;/strong&gt;&lt;/a&gt; showing how it works + &lt;strong&gt;Ollama example code&lt;/strong&gt; to implement the tool. Pro tip: Pair it with domain-specific prompts (like their airline policy examples) for max gains.&lt;/p&gt; &lt;p&gt;Is this &lt;em&gt;actually&lt;/em&gt; a breakthrough, or just hype? ü§î Early tests show big gains, but I‚Äôm curious:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Overkill for simple tasks?&lt;/strong&gt; (Anthropic admits it‚Äôs useless for one-shot tool calls)&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Anyone benchmarked it locally?&lt;/strong&gt; Share your results‚Äîdoes it really cut errors in complex workflows?&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Will OpenAI/others copy this?&lt;/strong&gt; (It‚Äôs just a JSON tool def, after all‚Ä¶)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Drop your takes below! üöÄ&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Straight-Worker-4327"&gt; /u/Straight-Worker-4327 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jiwadm/think_tool_boosts_accuracy_by_54_ollama/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jiwadm/think_tool_boosts_accuracy_by_54_ollama/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jiwadm/think_tool_boosts_accuracy_by_54_ollama/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T17:24:38+00:00</published>
  </entry>
  <entry>
    <id>t3_1jipzcb</id>
    <title>$2999 for Digits/Spark competitor from Asus</title>
    <updated>2025-03-24T12:55:25+00:00</updated>
    <author>
      <name>/u/DeltaSqueezer</name>
      <uri>https://old.reddit.com/user/DeltaSqueezer</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jipzcb/2999_for_digitsspark_competitor_from_asus/"&gt; &lt;img alt="$2999 for Digits/Spark competitor from Asus" src="https://external-preview.redd.it/D8QUMe074Ocrow6JjIZEcPidqg0czLoliY1NfSyw9QY.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=80b2510d09eaa83e23a59efd002b6c05c8748954" title="$2999 for Digits/Spark competitor from Asus" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/DeltaSqueezer"&gt; /u/DeltaSqueezer &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://www.techradar.com/pro/asus-debuts-its-own-mini-ai-supercomputer-ascent-gx10-costs-usd2999-and-comes-with-nvidias-gb10-grace-blackwell-superchip"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jipzcb/2999_for_digitsspark_competitor_from_asus/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jipzcb/2999_for_digitsspark_competitor_from_asus/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T12:55:25+00:00</published>
  </entry>
  <entry>
    <id>t3_1jivmy8</id>
    <title>Drummer's Fallen Command A 111B v1 - A big, bad, unhinged tune. An evil Behemoth.</title>
    <updated>2025-03-24T16:59:10+00:00</updated>
    <author>
      <name>/u/TheLocalDrummer</name>
      <uri>https://old.reddit.com/user/TheLocalDrummer</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jivmy8/drummers_fallen_command_a_111b_v1_a_big_bad/"&gt; &lt;img alt="Drummer's Fallen Command A 111B v1 - A big, bad, unhinged tune. An evil Behemoth." src="https://external-preview.redd.it/S7UO3mIB4z9Uh8ynqgmYcTGby2xdntT106INn_3Vnao.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=8b02dad91218e542d684307711478bfdc58133db" title="Drummer's Fallen Command A 111B v1 - A big, bad, unhinged tune. An evil Behemoth." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/TheLocalDrummer"&gt; /u/TheLocalDrummer &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://huggingface.co/TheDrummer/Fallen-Command-A-111B-v1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jivmy8/drummers_fallen_command_a_111b_v1_a_big_bad/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jivmy8/drummers_fallen_command_a_111b_v1_a_big_bad/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T16:59:10+00:00</published>
  </entry>
  <entry>
    <id>t3_1jioxj4</id>
    <title>Announcing TeapotLLM- an open-source ~800M model for hallucination-resistant Q&amp;A and document extraction, running entirely on CPU.</title>
    <updated>2025-03-24T11:59:40+00:00</updated>
    <author>
      <name>/u/zakerytclarke</name>
      <uri>https://old.reddit.com/user/zakerytclarke</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jioxj4/announcing_teapotllm_an_opensource_800m_model_for/"&gt; &lt;img alt="Announcing TeapotLLM- an open-source ~800M model for hallucination-resistant Q&amp;amp;A and document extraction, running entirely on CPU." src="https://external-preview.redd.it/3n5L3e5awOcQcEl4Nf4qqSOgiuX7eJUHzj2ZLltzndc.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=fbd66c6cac4856e8128e418bbe7a6f3172256e6d" title="Announcing TeapotLLM- an open-source ~800M model for hallucination-resistant Q&amp;amp;A and document extraction, running entirely on CPU." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/zakerytclarke"&gt; /u/zakerytclarke &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://huggingface.co/teapotai/teapotllm#evaluation"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jioxj4/announcing_teapotllm_an_opensource_800m_model_for/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jioxj4/announcing_teapotllm_an_opensource_800m_model_for/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T11:59:40+00:00</published>
  </entry>
  <entry>
    <id>t3_1jis4yh</id>
    <title>Deepseek V3-0324</title>
    <updated>2025-03-24T14:36:30+00:00</updated>
    <author>
      <name>/u/realJoeTrump</name>
      <uri>https://old.reddit.com/user/realJoeTrump</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jis4yh/deepseek_v30324/"&gt; &lt;img alt="Deepseek V3-0324" src="https://external-preview.redd.it/MzE3eWRta2JmbnFlMZasEx-JuE69Xxg53D-Z6l5VVnhhzxAjpdJ-bz7IYhTK.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=a946263616da361fcfb4f21438af02d13fd9bfd3" title="Deepseek V3-0324" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;WTF&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/realJoeTrump"&gt; /u/realJoeTrump &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/19vuv9ibfnqe1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jis4yh/deepseek_v30324/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jis4yh/deepseek_v30324/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T14:36:30+00:00</published>
  </entry>
  <entry>
    <id>t3_1jix2g7</id>
    <title>Qwen2.5-VL-32B-Instruct</title>
    <updated>2025-03-24T17:55:23+00:00</updated>
    <author>
      <name>/u/False_Care_2957</name>
      <uri>https://old.reddit.com/user/False_Care_2957</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jix2g7/qwen25vl32binstruct/"&gt; &lt;img alt="Qwen2.5-VL-32B-Instruct" src="https://b.thumbs.redditmedia.com/HcAA8XB1ZhY6C-KimtSV68cNZ3kUOZWKRsZCmScsHpE.jpg" title="Qwen2.5-VL-32B-Instruct" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://preview.redd.it/u7rpx7v8qoqe1.png?width=3081&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9e723b8f89af8b6dd13d8c3c7f21fe54269ef3a5"&gt;https://preview.redd.it/u7rpx7v8qoqe1.png?width=3081&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9e723b8f89af8b6dd13d8c3c7f21fe54269ef3a5&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Blog: &lt;a href="https://qwenlm.github.io/blog/qwen2.5-vl-32b/"&gt;https://qwenlm.github.io/blog/qwen2.5-vl-32b/&lt;/a&gt;&lt;br /&gt; HF: &lt;a href="https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct"&gt;https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/False_Care_2957"&gt; /u/False_Care_2957 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jix2g7/qwen25vl32binstruct/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jix2g7/qwen25vl32binstruct/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jix2g7/qwen25vl32binstruct/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T17:55:23+00:00</published>
  </entry>
  <entry>
    <id>t3_1jiqi81</id>
    <title>New deepseek v3 vs R1 (first is v3)</title>
    <updated>2025-03-24T13:20:54+00:00</updated>
    <author>
      <name>/u/cobalt1137</name>
      <uri>https://old.reddit.com/user/cobalt1137</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jiqi81/new_deepseek_v3_vs_r1_first_is_v3/"&gt; &lt;img alt="New deepseek v3 vs R1 (first is v3)" src="https://preview.redd.it/cvnu636y1nqe1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=7b35a3e96091f029004e4eb4290e5eae90de578a" title="New deepseek v3 vs R1 (first is v3)" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/cobalt1137"&gt; /u/cobalt1137 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/cvnu636y1nqe1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jiqi81/new_deepseek_v3_vs_r1_first_is_v3/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jiqi81/new_deepseek_v3_vs_r1_first_is_v3/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T13:20:54+00:00</published>
  </entry>
  <entry>
    <id>t3_1jisuq4</id>
    <title>DeepSeek V3-0324 has caught up to Sonnet 3.7 in my code creativity benchmark - "Write a raytracer that renders an interesting scene with many colourful lightsources in python."</title>
    <updated>2025-03-24T15:06:11+00:00</updated>
    <author>
      <name>/u/cpldcpu</name>
      <uri>https://old.reddit.com/user/cpldcpu</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jisuq4/deepseek_v30324_has_caught_up_to_sonnet_37_in_my/"&gt; &lt;img alt="DeepSeek V3-0324 has caught up to Sonnet 3.7 in my code creativity benchmark - &amp;quot;Write a raytracer that renders an interesting scene with many colourful lightsources in python.&amp;quot;" src="https://external-preview.redd.it/UVEiW2axvGQT_-A-QrSCYJfIlHr0MZzVYvUIPeOZnEI.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=5a8ffe19911392c13473b9c66e3fd7b50efa3454" title="DeepSeek V3-0324 has caught up to Sonnet 3.7 in my code creativity benchmark - &amp;quot;Write a raytracer that renders an interesting scene with many colourful lightsources in python.&amp;quot;" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;A while ago I set up a code creativity by asking various LLMs a very simple prompt:&lt;/p&gt; &lt;p&gt;&amp;gt; &lt;code&gt;Write a raytracer that renders an interesting scene with many colourful lightsources in python. Output a 800x600 image as a png&lt;/code&gt;&lt;/p&gt; &lt;p&gt;I only allowed one shot, no iterative prompting to solve broken code. What is interesting is that most LLMs generated code that created a very simple scene with a red, green and blue sphere, often also not aligned properly. Assumingly, the simple RGB example is something that is often represented in pretraining data.&lt;/p&gt; &lt;p&gt;Yet, somehow Sonnet 3.5 and especially Sonnet 3.7 created programs that generated more complex and varied scenes, using nicer colors. At the same time the filesize also increased. Anthropic had found some way to get the model to increase the creativity in coding and create more asthetic outcomes - no idea how to measure this other than looking at the images. (Speculation about how they did it and more ideas how to measure this are welcome in the comments)&lt;/p&gt; &lt;p&gt;Today I tested DeepSeek V3 0324 and it has definitely caught up to 3.7, a huge improvement over V3!&lt;/p&gt; &lt;p&gt;Benchmark data and more information &lt;a href="https://github.com/cpldcpu/llmbenchmark/blob/master/raytracer/Readme.md"&gt;here&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/4nsm9rbaknqe1.png?width=1293&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=da86b326644f473a6814fc444b1d4b67a17941ee"&gt;Variance test where every LLM is prompted 4 times&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/9acauhqcknqe1.png?width=1302&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=dcbebb2bfb5ce33f53e31e9e1c0facb013a5b9a8"&gt;Summary of all tested LLMs&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/cpldcpu"&gt; /u/cpldcpu &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jisuq4/deepseek_v30324_has_caught_up_to_sonnet_37_in_my/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jisuq4/deepseek_v30324_has_caught_up_to_sonnet_37_in_my/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jisuq4/deepseek_v30324_has_caught_up_to_sonnet_37_in_my/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T15:06:11+00:00</published>
  </entry>
  <entry>
    <id>t3_1jip611</id>
    <title>Deepseek releases new V3 checkpoint (V3-0324)</title>
    <updated>2025-03-24T12:12:24+00:00</updated>
    <author>
      <name>/u/paf1138</name>
      <uri>https://old.reddit.com/user/paf1138</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jip611/deepseek_releases_new_v3_checkpoint_v30324/"&gt; &lt;img alt="Deepseek releases new V3 checkpoint (V3-0324)" src="https://external-preview.redd.it/L_MDAztp6gi49dQUv9vk2IeXw1OjSoBT_ooENnggvOg.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=94d961b0b48a76bd398ef8e9a387f6a5087e577d" title="Deepseek releases new V3 checkpoint (V3-0324)" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/paf1138"&gt; /u/paf1138 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://huggingface.co/deepseek-ai/DeepSeek-V3-0324"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1jip611/deepseek_releases_new_v3_checkpoint_v30324/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1jip611/deepseek_releases_new_v3_checkpoint_v30324/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-03-24T12:12:24+00:00</published>
  </entry>
</feed>
